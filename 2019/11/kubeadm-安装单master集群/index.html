<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>kubeadm 安装单master集群 - 戴先森的学习笔记</title><meta name="Description" content="戴先森的学习笔记"><meta property="og:title" content="kubeadm 安装单master集群" />
<meta property="og:description" content="环境准备 系统及软件版本 kubernetes version: v1.16.3 组件 版本 说明 Centos 7.7 操作系统 kubeadm v1.16.3 集群部署工具 etcd 3.3.15 存储数据库 calico v3.14.0 CNI 网络插件 docker 18.09.9 CRI Runtime metallb v0.8.3 穷人版 LoadBalancer 主机列表 hostname IP Address components k8s-master 10.64.144.100 kube-apiserver,kube-controller-manager,kube-scheduler,etcd,kubelet,flannel,docker k8s-node01" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://linuxyunwei.com/2019/11/kubeadm-%E5%AE%89%E8%A3%85%E5%8D%95master%E9%9B%86%E7%BE%A4/" />
<meta property="article:published_time" content="2019-11-18T19:12:02+08:00" />
<meta property="article:modified_time" content="2020-05-20T17:34:07+08:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="kubeadm 安装单master集群"/>
<meta name="twitter:description" content="环境准备 系统及软件版本 kubernetes version: v1.16.3 组件 版本 说明 Centos 7.7 操作系统 kubeadm v1.16.3 集群部署工具 etcd 3.3.15 存储数据库 calico v3.14.0 CNI 网络插件 docker 18.09.9 CRI Runtime metallb v0.8.3 穷人版 LoadBalancer 主机列表 hostname IP Address components k8s-master 10.64.144.100 kube-apiserver,kube-controller-manager,kube-scheduler,etcd,kubelet,flannel,docker k8s-node01"/>
<meta name="application-name" content="LoveIt">
<meta name="apple-mobile-web-app-title" content="LoveIt"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://linuxyunwei.com/2019/11/kubeadm-%E5%AE%89%E8%A3%85%E5%8D%95master%E9%9B%86%E7%BE%A4/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "kubeadm 安装单master集群",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/linuxyunwei.com\/2019\/11\/kubeadm-%E5%AE%89%E8%A3%85%E5%8D%95master%E9%9B%86%E7%BE%A4\/"
        },"image": {
                "@type": "ImageObject",
                "url": "https:\/\/linuxyunwei.com\/cover.png",
                "width":  800 ,
                "height":  600 
            },"genre": "posts","keywords": "kubernetes","wordcount":  8392 ,
        "url": "https:\/\/linuxyunwei.com\/2019\/11\/kubeadm-%E5%AE%89%E8%A3%85%E5%8D%95master%E9%9B%86%E7%BE%A4\/","datePublished": "2019-11-18T19:12:02+08:00","dateModified": "2020-05-20T17:34:07+08:00","publisher": {
                "@type": "Organization",
                "name": "xxxx",
                "logo": {
                "@type": "ImageObject",
                "url": "https:\/\/linuxyunwei.com\/logo.png",
                "width":  127 ,
                "height":  40 
                }
            },"author": {
                "@type": "Person",
                "name": "戴先森"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="戴先森的学习笔记"></a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/"> 首页 </a><a class="menu-item" href="/posts/"> 文章列表 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="戴先森的学习笔记"></a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/" title="">首页</a><a class="menu-item" href="/posts/" title="">文章列表</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">kubeadm 安装单master集群</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>戴先森</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/kubernetes/"><i class="far fa-folder fa-fw"></i>kubernetes</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2019-11-18">2019-11-18</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 8392 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 17 分钟&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#环境准备">环境准备</a>
      <ul>
        <li><a href="#系统及软件版本">系统及软件版本</a></li>
        <li><a href="#主机列表">主机列表</a></li>
        <li><a href="#网络规划">网络规划</a></li>
      </ul>
    </li>
    <li><a href="#系统初始化">系统初始化</a>
      <ul>
        <li><a href="#配置-hosts-同步">配置 hosts 同步</a></li>
        <li><a href="#设置主机名">设置主机名</a></li>
        <li><a href="#更新系统">更新系统</a></li>
        <li><a href="#更新内核">更新内核</a></li>
        <li><a href="#重启后验证内核版本">重启后验证内核版本</a></li>
        <li><a href="#禁用-selinux">禁用 SELinux</a></li>
        <li><a href="#禁用-swap">禁用 swap</a></li>
        <li><a href="#禁用不需要的服务">禁用不需要的服务</a></li>
        <li><a href="#安装必要工具">安装必要工具</a></li>
        <li><a href="#优化系统内核">优化系统内核</a></li>
        <li><a href="#开启-ipvs-支持">开启 ipvs 支持</a></li>
        <li><a href="#时间同步">时间同步</a></li>
        <li><a href="#运行-docker-检测脚本">运行 docker 检测脚本</a></li>
        <li><a href="#重启系统">重启系统</a></li>
      </ul>
    </li>
    <li><a href="#安装-docker">安装 Docker</a>
      <ul>
        <li><a href="#安装">安装</a></li>
        <li><a href="#修改配置文件">修改配置文件</a></li>
        <li><a href="#启动并检查配置是否生效">启动并检查配置是否生效</a></li>
      </ul>
    </li>
    <li><a href="#安装-kubernetes-相关工具">安装 kubernetes 相关工具</a>
      <ul>
        <li><a href="#添加阿里云-yum-源">添加阿里云 YUM 源</a></li>
        <li><a href="#查看支持的版本列表">查看支持的版本列表</a></li>
        <li><a href="#安装-kubeadmkubectlkubelet-工具">安装 kubeadm、kubectl、kubelet 工具</a></li>
        <li><a href="#添加-kubelet-开机自启动">添加 kubelet 开机自启动</a></li>
      </ul>
    </li>
    <li><a href="#初始化集群">初始化集群</a>
      <ul>
        <li><a href="#生成-kubeadm-配置文件">生成 kubeadm 配置文件</a></li>
        <li><a href="#修改配置">修改配置</a></li>
        <li><a href="#下载所需镜像可选">下载所需镜像(可选)</a></li>
        <li><a href="#初始化">初始化</a></li>
        <li><a href="#配置-kubeconfig">配置 kubeconfig</a></li>
      </ul>
    </li>
    <li><a href="#加入-worker-节点到集群">加入 worker 节点到集群</a></li>
    <li><a href="#安装-cni-网络插件">安装 CNI 网络插件</a>
      <ul>
        <li><a href="#下载-calicoyaml">下载 calico.yaml</a></li>
        <li><a href="#部署">部署</a></li>
        <li><a href="#通过-calicoctl-查看-bgp-节点状态">通过 calicoctl 查看 BGP 节点状态</a></li>
        <li><a href="#确认查看集群状态">确认查看集群状态</a></li>
      </ul>
    </li>
    <li><a href="#配置节点之间流量加密-可选">配置节点之间流量加密 (可选)</a></li>
    <li><a href="#测试">测试</a>
      <ul>
        <li><a href="#创建-pod-测试集群是否能正常工作">创建 pod 测试集群是否能正常工作</a></li>
        <li><a href="#测试-coredns-能否正常工作">测试 coredns 能否正常工作</a></li>
      </ul>
    </li>
    <li><a href="#安装-ingress">安装 Ingress</a></li>
    <li><a href="#部署-metallb">部署 Metallb</a></li>
    <li><a href="#测试-ingress-nginx-及-metallb">测试 ingress-nginx 及 metallb</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h2 id="环境准备">环境准备</h2>
<h3 id="系统及软件版本">系统及软件版本</h3>
<blockquote>
<p>kubernetes version: v1.16.3</p>
</blockquote>
<table>
<thead>
<tr>
<th>组件</th>
<th>版本</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Centos</td>
<td>7.7</td>
<td>操作系统</td>
</tr>
<tr>
<td>kubeadm</td>
<td>v1.16.3</td>
<td>集群部署工具</td>
</tr>
<tr>
<td>etcd</td>
<td>3.3.15</td>
<td>存储数据库</td>
</tr>
<tr>
<td>calico</td>
<td>v3.14.0</td>
<td>CNI 网络插件</td>
</tr>
<tr>
<td>docker</td>
<td>18.09.9</td>
<td>CRI Runtime</td>
</tr>
<tr>
<td>metallb</td>
<td>v0.8.3</td>
<td>穷人版 LoadBalancer</td>
</tr>
</tbody>
</table>
<h3 id="主机列表">主机列表</h3>
<table>
<thead>
<tr>
<th>hostname</th>
<th>IP Address</th>
<th>components</th>
</tr>
</thead>
<tbody>
<tr>
<td>k8s-master</td>
<td>10.64.144.100</td>
<td>kube-apiserver,kube-controller-manager,kube-scheduler,etcd,kubelet,flannel,docker</td>
</tr>
<tr>
<td>k8s-node01</td>
<td>10.64.144.101</td>
<td>kube-proxy,kubelet,flannel,docker</td>
</tr>
<tr>
<td>k8s-node02</td>
<td>10.64.144.102</td>
<td>kube-proxy,kubelet,flannel,docker</td>
</tr>
<tr>
<td>k8s-node03</td>
<td>10.64.144.103</td>
<td>kube-proxy,kubelet,flannel,docker</td>
</tr>
<tr>
<td>k8s-node04</td>
<td>10.64.144.104</td>
<td>kube-proxy,kubelet,flannel,docker</td>
</tr>
<tr>
<td>k8s-node05</td>
<td>10.64.144.105</td>
<td>kube-proxy,kubelet,flannel,docker</td>
</tr>
<tr>
<td>k8s-node06</td>
<td>10.64.144.106</td>
<td>kube-proxy,kubelet,flannel,docker</td>
</tr>
</tbody>
</table>
<h3 id="网络规划">网络规划</h3>
<table>
<thead>
<tr>
<th>功能</th>
<th>网段</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pod 网络</td>
<td>172.16.0.0/16</td>
</tr>
<tr>
<td>Service 网络</td>
<td>10.96.0.0/12</td>
</tr>
<tr>
<td>DNS 地址</td>
<td>10.96.0.10</td>
</tr>
<tr>
<td>LoadBalance</td>
<td>10.64.144.150~10.64.144.200</td>
</tr>
</tbody>
</table>
<h2 id="系统初始化">系统初始化</h2>
<blockquote>
<p>所有节点上都需要操作</p>
</blockquote>
<h3 id="配置-hosts-同步">配置 hosts 同步</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ cat &gt; /etc/hosts <span class="s">&lt;&lt;EOF
</span><span class="s">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
</span><span class="s">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
</span><span class="s">10.64.144.100   k8s-master
</span><span class="s">10.64.144.101   k8s-node01
</span><span class="s">10.64.144.102   k8s-node02
</span><span class="s">10.64.144.103   k8s-node03
</span><span class="s">10.64.144.104   k8s-node04
</span><span class="s">10.64.144.105   k8s-node05
</span><span class="s">10.64.144.106   k8s-node06
</span><span class="s">EOF</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="设置主机名">设置主机名</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">hostnamectl set-hostname k8s-master <span class="c1"># 分别设置所有节点的主机名</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="更新系统">更新系统</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">yum update -y
</code></pre></td></tr></table>
</div>
</div><h3 id="更新内核">更新内核</h3>
<p>安装稳定版主线内核</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
yum install -y https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm
yum install -y --enablerepo<span class="o">=</span>elrepo-kernel kernel-ml kernel-ml-headers kernel-ml-devel
</code></pre></td></tr></table>
</div>
</div><p>查看系统中已安装的内核版本</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ awk -F<span class="se">\&#39;</span> <span class="s1">&#39;$1==&#34;menuentry &#34; {print i++ &#34; : &#34; $2}&#39;</span> /etc/grub2.cfg
<span class="m">0</span> : CentOS Linux <span class="o">(</span>5.6.13-1.el7.elrepo.x86_64<span class="o">)</span> <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>
<span class="m">1</span> : CentOS Linux <span class="o">(</span>3.10.0-1062.4.1.el7.x86_64<span class="o">)</span> <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>
<span class="m">2</span> : CentOS Linux <span class="o">(</span>3.10.0-957.el7.x86_64<span class="o">)</span> <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>
<span class="m">3</span> : CentOS Linux <span class="o">(</span>0-rescue-4097349c950a4862a8fab2587d598af7<span class="o">)</span> <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>
</code></pre></td></tr></table>
</div>
</div><p>切换默认内核</p>
<blockquote>
<p><code>0</code> 为上面列出的序号，比如我这里 <code>0</code> 代表 <code>5.6.13</code> 这个版本的内核</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ grub2-set-default <span class="m">0</span>
$ grub2-mkconfig -o /boot/grub2/grub.cfg
Generating grub configuration file ...
Found linux image: /boot/vmlinuz-5.6.13-1.el7.elrepo.x86_64
Found initrd image: /boot/initramfs-5.6.13-1.el7.elrepo.x86_64.img
Found linux image: /boot/vmlinuz-3.10.0-1062.4.1.el7.x86_64
Found initrd image: /boot/initramfs-3.10.0-1062.4.1.el7.x86_64.img
Found linux image: /boot/vmlinuz-3.10.0-957.el7.x86_64
Found initrd image: /boot/initramfs-3.10.0-957.el7.x86_64.img
Found linux image: /boot/vmlinuz-0-rescue-4097349c950a4862a8fab2587d598af7
Found initrd image: /boot/initramfs-0-rescue-4097349c950a4862a8fab2587d598af7.img
<span class="k">done</span>
</code></pre></td></tr></table>
</div>
</div><blockquote>
<p>实验环境中由于使用的是普通 PC， 所以还需要安装网卡驱动 <code>kmod-r8168</code>, <code>kmod-r8169</code></p>
</blockquote>
<h3 id="重启后验证内核版本">重启后验证内核版本</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ uname -r
5.6.13-1.el7.elrepo.x86_64
</code></pre></td></tr></table>
</div>
</div><h3 id="禁用-selinux">禁用 SELinux</h3>
<p>如果不禁用 selinux，挂载目录会出现 <code>Permission deined</code> 错误</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">sed -i <span class="s1">&#39;s/SELINUX=enforcing/SELINUX=disabled/g&#39;</span> /etc/selinux/config  <span class="c1"># 永久关闭</span>
setenforce <span class="m">0</span>  <span class="c1"># 临时关闭</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="禁用-swap">禁用 swap</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">swapoff -a
sed -i -r <span class="s1">&#39;s/(.+ swap .*)/# \1/&#39;</span> /etc/fstab
sysctl -w vm.swappiness<span class="o">=</span><span class="m">0</span>
cat &gt; /etc/sysctl.d/swap.conf <span class="s">&lt;&lt;EOF
</span><span class="s">vm.swappiness=0
</span><span class="s">EOF</span>
sysctl -p /etc/sysctl.d/swap.conf
</code></pre></td></tr></table>
</div>
</div><h3 id="禁用不需要的服务">禁用不需要的服务</h3>
<p>如果选择不关闭<code>firewalld</code>，请参考官方文档中放行相应的端口 <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#check-required-ports" target="_blank" rel="noopener noreffer">check-required-ports</a></p>
<p>最少化安装的 Centos 中貌似没有安装 dnsmasq，如果有安装则需要将其禁用，否则它会把节点上的 DNS server 设置为 127.0.0.1,将会导致 Docker 无法解析域名</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">systemctl disable --now firewalld NetworkManager dnsmasq
</code></pre></td></tr></table>
</div>
</div><h3 id="安装必要工具">安装必要工具</h3>
<p>kube-proxy 的 ipvs 模式下依赖<code>ipvsadm</code>,<code>ipset</code>用于配置及管理规则</p>
<p><code>kubectl port-forward</code>命令依赖<code>socat</code>做端口转发</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">yum install -y ipvsadm ipset sysstat conntrack libseccomp socat wget git jq curl
</code></pre></td></tr></table>
</div>
</div><h3 id="优化系统内核">优化系统内核</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ cat &gt; /etc/sysctl.d/k8s.conf <span class="s">&lt;&lt;EOF
</span><span class="s"># https://github.com/moby/moby/issues/31208
</span><span class="s"># ipvsadm -l --timout
</span><span class="s"># 修复ipvs模式下长连接timeout问题 小于900即可
</span><span class="s">net.ipv4.tcp_keepalive_time = 600
</span><span class="s">net.ipv4.tcp_keepalive_intvl = 30
</span><span class="s">net.ipv4.tcp_keepalive_probes = 10
</span><span class="s"># 关闭ipv6
</span><span class="s">net.ipv6.conf.all.disable_ipv6 = 1
</span><span class="s">net.ipv6.conf.default.disable_ipv6 = 1
</span><span class="s">net.ipv6.conf.lo.disable_ipv6 = 1
</span><span class="s">net.ipv4.neigh.default.gc_stale_time = 120
</span><span class="s">net.ipv4.conf.all.rp_filter = 0
</span><span class="s">net.ipv4.conf.default.rp_filter = 0
</span><span class="s">net.ipv4.conf.default.arp_announce = 2
</span><span class="s">net.ipv4.conf.lo.arp_announce = 2
</span><span class="s">net.ipv4.conf.all.arp_announce = 2
</span><span class="s"># 开启路由转发
</span><span class="s">net.ipv4.ip_forward = 1
</span><span class="s">net.ipv4.tcp_max_tw_buckets = 5000
</span><span class="s">net.ipv4.tcp_syncookies = 1
</span><span class="s">net.ipv4.tcp_max_syn_backlog = 1024
</span><span class="s">net.ipv4.tcp_synack_retries = 2
</span><span class="s"># 开启 bridge-netfilter, 使用iptables规则可以作用于bridge模式
</span><span class="s">net.bridge.bridge-nf-call-ip6tables = 1
</span><span class="s">net.bridge.bridge-nf-call-iptables = 1
</span><span class="s">net.bridge.bridge-nf-call-arptables = 1
</span><span class="s">net.netfilter.nf_conntrack_max = 2310720
</span><span class="s">fs.inotify.max_user_watches=89100
</span><span class="s">fs.may_detach_mounts = 1
</span><span class="s">fs.file-max = 52706963
</span><span class="s">fs.nr_open = 52706963
</span><span class="s">vm.overcommit_memory=1
</span><span class="s">vm.panic_on_oom=0
</span><span class="s">EOF</span>
$ sysctl --system  <span class="c1"># 使配置生效</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="开启-ipvs-支持">开启 ipvs 支持</h3>
<blockquote>
<p>如果内核版本小于 <code>4.19</code>, 需要将 <code>nf_conntrack</code> 修改为 <code>nf_conntrack_ipv4</code></p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="c1"># 临时生效</span>
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack

<span class="c1"># 永久生效</span>
$ cat &gt; /etc/sysconfig/modules/ipvs.modules <span class="s">&lt;&lt;&#39;EOF&#39;
</span><span class="s">#!/bin/sh
</span><span class="s">modules=(
</span><span class="s">ip_vs
</span><span class="s">ip_vs_rr
</span><span class="s">ip_vs_wrr
</span><span class="s">ip_vs_sh
</span><span class="s">nf_conntrack_ipv4
</span><span class="s">br_netfilter
</span><span class="s">)
</span><span class="s">for mod in ${modules[@]}
</span><span class="s">do
</span><span class="s">  /sbin/modinfo -F filename ${mod} &gt; /dev/null 2&gt;&amp;1
</span><span class="s">  if [ $? -eq 0 ]
</span><span class="s">  then
</span><span class="s">      /sbin/modprobe ${mod}
</span><span class="s">  fi
</span><span class="s">done
</span><span class="s">EOF</span>
chmod +x /etc/sysconfig/modules/ipvs.modules

<span class="c1"># 检查内核模块是否已经加载</span>
$ lsmod <span class="p">|</span> grep ip_vs
ip_vs_sh               <span class="m">12688</span>  <span class="m">0</span>
ip_vs_wrr              <span class="m">12697</span>  <span class="m">0</span>
ip_vs_rr               <span class="m">12600</span>  <span class="m">4</span>
ip_vs                 <span class="m">145497</span>  <span class="m">10</span> ip_vs_rr,ip_vs_sh,ip_vs_wrr
nf_conntrack          <span class="m">139224</span>  <span class="m">7</span> ip_vs,nf_nat,nf_nat_ipv4,xt_conntrack,nf_nat_masquerade_ipv4,nf_conntrack_netlink,nf_conntrack
libcrc32c              <span class="m">12644</span>  <span class="m">4</span> xfs,ip_vs,nf_nat,nf_conntrack
</code></pre></td></tr></table>
</div>
</div><h3 id="时间同步">时间同步</h3>
<p>所有节点配置为同一时区，并使用 <code>chrony</code> 同步节点的时间</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
$ <span class="nb">echo</span> <span class="s2">&#34;Asia/Shanghai&#34;</span> &gt; /etc/timezone
$ yum install chrony -y
$ cat &gt; /etc/chrony.conf <span class="s">&lt;&lt;EOF
</span><span class="s">server ntp.aliyun.com iburst
</span><span class="s">stratumweight 0
</span><span class="s">driftfile /var/lib/chrony/drift
</span><span class="s">rtcsync
</span><span class="s">makestep 10 3
</span><span class="s">bindcmdaddress 127.0.0.1
</span><span class="s">bindcmdaddress ::1
</span><span class="s">keyfile /etc/chrony.keys
</span><span class="s">commandkey 1
</span><span class="s">generatecommandkey
</span><span class="s">logchange 0.5
</span><span class="s">logdir /var/log/chrony
</span><span class="s">EOF</span>
$ systemctl <span class="nb">enable</span> --now chronyd
</code></pre></td></tr></table>
</div>
</div><h3 id="运行-docker-检测脚本">运行 docker 检测脚本</h3>
<p>docker 官方提供了脚本用于检查内核相关配置</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="hl"><span class="lnt"> 9
</span></span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell"><span class="se">\$</span> curl -fsSL https://raw.githubusercontent.com/moby/moby/master/contrib/check-config.sh <span class="p">|</span> bash -s
info: reading kernel config from /boot/config-3.10.0-1062.4.3.el7.x86_64 ...

Generally Necessary:
...

Optional Features:

<span class="hl">- CONFIG_USER_NS: enabled
</span>  <span class="o">(</span>RHEL7/CentOS7: User namespaces disabled<span class="p">;</span> add <span class="s1">&#39;user_namespace.enable=1&#39;</span> to boot <span class="nb">command</span> line<span class="o">)</span>
- CONFIG_SECCOMP: enabled
  ...
  </code></pre></td></tr></table>
</div>
</div>
<p>如上高亮行所示，开启 user_namespace</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ grubby --args<span class="o">=</span><span class="s2">&#34;user_namespace.enable=1&#34;</span> --update-kernel<span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span>grubby --default-kernel<span class="k">)</span><span class="s2">&#34;</span>
$ grep user_namespace /etc/grub2.cfg
        linux16 /vmlinuz-5.6.13-1.el7.elrepo.x86_64 <span class="nv">root</span><span class="o">=</span>/dev/mapper/centos-root ro <span class="nv">crashkernel</span><span class="o">=</span>auto rd.lvm.lv<span class="o">=</span>centos/root rhgb quiet user_namespace.enable<span class="o">=</span><span class="m">1</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="重启系统">重启系统</h3>
<p>重启系统以使配置生效</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">systemctl reboot
</code></pre></td></tr></table>
</div>
</div><h2 id="安装-docker">安装 Docker</h2>
<blockquote>
<p>所有节点上均需配置</p>
</blockquote>
<p>虽然 Kubernetes 支持多种容器运行环境，如 <code>Docker</code>, <code>Containerd</code>, <code>CRI-O</code> 等，但目前 <code>Docker</code> 还是主流</p>
<p>关于容器运行环境可以参考官方文档 <a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/" target="_blank" rel="noopener noreffer">Container Runntimes</a></p>
<p>支持的 Docker 版本列表请查看官方 <a href="https://github.com/kubernetes/kubernetes/blob/v1.16.3/CHANGELOG-1.16.md" target="_blank" rel="noopener noreffer">CHANGELOG</a> 搜索 <code>The list of validated docker versions</code> 关键字</p>
<h3 id="安装">安装</h3>
<p>官方推荐使用 <code>18.06.2</code>, 我这里使用的是 <code>18.09.9</code></p>
<p>Docker 官方的 yum 源在国内可能会访问不到，这里使用了阿里云的镜像源</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">yum install -y yum-utils device-mapper-persistent-data lvm2
<span class="nb">export</span> <span class="nv">VERSION</span><span class="o">=</span>18.09
curl -fsSL https://get.docker.com <span class="p">|</span> bash -s docker --mirror Aliyun
</code></pre></td></tr></table>
</div>
</div><h3 id="修改配置文件">修改配置文件</h3>
<p>主要修改以下几个参数:</p>
<ul>
<li><code>native.cgroupdriver</code>: 官方推荐使用 <code>systemd</code> 来管理 cgroup,且必须与 kubelet 的<code>--cgroup-driver</code>参数一致</li>
<li><code>storage-driver</code>: 存储驱动，<code>overlay2</code> 会比其他驱动更好的性能。如果文件系统为<code>XFS</code>，请确保<code>ftype=1</code>(可使用 <code>xfs_info</code> 查看),否则 docker 会无法启动，报错信息<code>Error starting daemon: error initializing graphdriver: overlay2: the backing xfs filesystem is formatted without d_type support, which leads to incorrect behavior. Reformat the filesystem with ftype=1 to enable d_type support. Backing filesystems without d_type support are not supported.</code></li>
<li><code>registry-mirrors</code>: 加速从 dockerhub 拉取镜像</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">mkdir /etc/docker
cat &gt; /etc/docker/daemon.json <span class="s">&lt;&lt;EOF
</span><span class="s">{
</span><span class="s">  &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;],
</span><span class="s">  &#34;registry-mirrors&#34;: [&#34;https://8jg6za8m.mirror.aliyuncs.com&#34;],
</span><span class="s">  &#34;storage-driver&#34;: &#34;overlay2&#34;,
</span><span class="s">  &#34;storage-opts&#34;: [
</span><span class="s">    &#34;overlay2.override_kernel_check=true&#34;
</span><span class="s">  ],
</span><span class="s">  &#34;log-driver&#34;: &#34;json-file&#34;,
</span><span class="s">  &#34;log-opts&#34;: {
</span><span class="s">    &#34;max-size&#34;: &#34;100m&#34;,
</span><span class="s">    &#34;max-file&#34;: &#34;3&#34;
</span><span class="s">  }
</span><span class="s">}
</span><span class="s">EOF</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="启动并检查配置是否生效">启动并检查配置是否生效</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ systemctl <span class="nb">enable</span> --now docker
Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.
$ docker version
Client:
 Version:           18.09.9
 API version:       1.39
 Go version:        go1.11.13
 Git commit:        039a7df9ba
 Built:             Wed Sep  <span class="m">4</span> 16:51:21 <span class="m">2019</span>
 OS/Arch:           linux/amd64
 Experimental:      <span class="nb">false</span>

Server: Docker Engine - Community
 Engine:
  Version:          18.09.9
  API version:      1.39 <span class="o">(</span>minimum version 1.12<span class="o">)</span>
  Go version:       go1.11.13
  Git commit:       039a7df
  Built:            Wed Sep  <span class="m">4</span> 16:22:32 <span class="m">2019</span>
  OS/Arch:          linux/amd64
  Experimental:     <span class="nb">false</span>
$ docker info
Containers: <span class="m">0</span>
 Running: <span class="m">0</span>
 Paused: <span class="m">0</span>
 Stopped: <span class="m">0</span>
Images: <span class="m">0</span>
Server Version: 18.09.9
Storage Driver: overlay2
 Backing Filesystem: xfs
 Supports d_type: <span class="nb">true</span>
 Native Overlay Diff: <span class="nb">true</span>
Logging Driver: json-file
Cgroup Driver: systemd
Plugins:
 Volume: <span class="nb">local</span>
 Network: bridge host macvlan null overlay
 Log: awslogs fluentd gcplogs gelf journald json-file <span class="nb">local</span> logentries splunk syslog
Swarm: inactive
Runtimes: runc
Default Runtime: runc
Init Binary: docker-init
containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339
runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657
init version: fec3683
Security Options:
 seccomp
  Profile: default
Kernel Version: 5.6.13-1.el7.elrepo.x86_64
Operating System: CentOS Linux <span class="m">7</span> <span class="o">(</span>Core<span class="o">)</span>
OSType: linux
Architecture: x86_64
CPUs: <span class="m">4</span>
Total Memory: 15.39GiB
Name: k8s-master
ID: BI53:OQC7:QV6C:SP3N:FBTT:N5ST:MK3I:CGLJ:X2JX:CJOH:CBEE:4GG2
Docker Root Dir: /var/lib/docker
Debug Mode <span class="o">(</span>client<span class="o">)</span>: <span class="nb">false</span>
Debug Mode <span class="o">(</span>server<span class="o">)</span>: <span class="nb">false</span>
Registry: https://index.docker.io/v1/
Labels:
Experimental: <span class="nb">false</span>
Insecure Registries:
 127.0.0.0/8
Registry Mirrors:
 https://8jg6za8m.mirror.aliyuncs.com/
Live Restore Enabled: <span class="nb">false</span>
Product License: Community Engine
</code></pre></td></tr></table>
</div>
</div><h2 id="安装-kubernetes-相关工具">安装 kubernetes 相关工具</h2>
<blockquote>
<p>所有节点上操作</p>
</blockquote>
<h3 id="添加阿里云-yum-源">添加阿里云 YUM 源</h3>
<p>默认官方的源在国内环境下可能会访问不到</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">cat &gt; /etc/yum.repos.d/kubernetes.repo <span class="s">&lt;&lt;EOF
</span><span class="s">[kubernetes]
</span><span class="s">name=Kubernetes
</span><span class="s">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
</span><span class="s">enabled=1
</span><span class="s">gpgcheck=1
</span><span class="s">repo_gpgcheck=1
</span><span class="s">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
</span><span class="s">EOF</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="查看支持的版本列表">查看支持的版本列表</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ yum --disablerepo<span class="o">=</span><span class="s2">&#34;*&#34;</span> --enablerepo<span class="o">=</span><span class="s2">&#34;kubernetes&#34;</span> list available --showduplicates  <span class="p">|</span> grep <span class="s2">&#34;1.16&#34;</span>
kubeadm.x86_64                       1.16.0-0                         kubernetes
kubeadm.x86_64                       1.16.1-0                         kubernetes
kubeadm.x86_64                       1.16.2-0                         kubernetes
kubeadm.x86_64                       1.16.3-0                         kubernetes
kubectl.x86_64                       1.16.0-0                         kubernetes
kubectl.x86_64                       1.16.1-0                         kubernetes
kubectl.x86_64                       1.16.2-0                         kubernetes
kubectl.x86_64                       1.16.3-0                         kubernetes
kubelet.x86_64                       1.16.0-0                         kubernetes
kubelet.x86_64                       1.16.1-0                         kubernetes
kubelet.x86_64                       1.16.2-0                         kubernetes
kubelet.x86_64                       1.16.3-0                         kubernetes
</code></pre></td></tr></table>
</div>
</div><h3 id="安装-kubeadmkubectlkubelet-工具">安装 kubeadm、kubectl、kubelet 工具</h3>
<blockquote>
<p>本次安装 <code>1.16.3</code> 版本</p>
</blockquote>
<p>worker 节点可以不安装 kubectl</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">yum install kubeadm-1.16.3 kubectl-1.16.3 kubelet-1.16.3 -y
</code></pre></td></tr></table>
</div>
</div><h3 id="添加-kubelet-开机自启动">添加 kubelet 开机自启动</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ systemctl <span class="nb">enable</span> --now kubelet
Created symlink from /etc/systemd/system/multi-user.target.wants/kubelet.service to /usr/lib/systemd/system/kubelet.service.
$ systemctl status kubelet
● kubelet.service - kubelet: The Kubernetes Node Agent
   Loaded: loaded <span class="o">(</span>/usr/lib/systemd/system/kubelet.service<span class="p">;</span> enabled<span class="p">;</span> vendor preset: disabled<span class="o">)</span>
  Drop-In: /usr/lib/systemd/system/kubelet.service.d
           └─10-kubeadm.conf
   Active: activating <span class="o">(</span>auto-restart<span class="o">)</span> <span class="o">(</span>Result: exit-code<span class="o">)</span> since Thu 2019-11-21 10:27:34 CST<span class="p">;</span> 898ms ago
     Docs: https://kubernetes.io/docs/
  Process: <span class="m">3947</span> <span class="nv">ExecStart</span><span class="o">=</span>/usr/bin/kubelet <span class="nv">$KUBELET_KUBECONFIG_ARGS</span> <span class="nv">$KUBELET_CONFIG_ARGS</span> <span class="nv">$KUBELET_KUBEADM_ARGS</span> <span class="nv">$KUBELET_EXTRA_ARGS</span> <span class="o">(</span><span class="nv">code</span><span class="o">=</span>exited, <span class="nv">status</span><span class="o">=</span>255<span class="o">)</span>
 Main PID: <span class="m">3947</span> <span class="o">(</span><span class="nv">code</span><span class="o">=</span>exited, <span class="nv">status</span><span class="o">=</span>255<span class="o">)</span>

Nov <span class="m">21</span> 10:27:34 k8s-master systemd<span class="o">[</span>1<span class="o">]</span>: Unit kubelet.service entered failed state.
Nov <span class="m">21</span> 10:27:34 k8s-master systemd<span class="o">[</span>1<span class="o">]</span>: kubelet.service failed.
</code></pre></td></tr></table>
</div>
</div><p>如上查看服务状态你会发现启动失败，不过没关系，这里可以暂时忽略，因为我们还没开始初始化集群，所以还没有生成<code>kubelet</code>的配置文件</p>
<p>如果 enable 时提示 <code>Unit kubelet.service could not be found.</code>，执行<code>systemctl daemon-reload</code>重载配置就可以了</p>
<h2 id="初始化集群">初始化集群</h2>
<blockquote>
<p>在 master 上操作</p>
</blockquote>
<h3 id="生成-kubeadm-配置文件">生成 kubeadm 配置文件</h3>
<p>生成默认配置</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">kubeadm config print init-defaults --component-configs KubeProxyConfiguration,KubeletConfiguration &gt; kubeadm-config.yaml
</code></pre></td></tr></table>
</div>
</div><h3 id="修改配置">修改配置</h3>
<p>主要改动如下:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="hl"><span class="lnt">  5
</span></span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="hl"><span class="lnt"> 12
</span></span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="hl"><span class="lnt"> 32
</span></span><span class="lnt"> 33
</span><span class="hl"><span class="lnt"> 34
</span></span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="hl"><span class="lnt"> 37
</span></span><span class="hl"><span class="lnt"> 38
</span></span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="hl"><span class="lnt"> 49
</span></span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="hl"><span class="lnt"> 72
</span></span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="hl"><span class="lnt"> 97
</span></span><span class="hl"><span class="lnt"> 98
</span></span><span class="hl"><span class="lnt"> 99
</span></span><span class="hl"><span class="lnt">100
</span></span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="k">apiVersion</span><span class="p">:</span><span class="w"> </span>kubeadm.k8s.io/v1beta2<span class="w">
</span><span class="w"></span><span class="k">bootstrapTokens</span><span class="p">:</span><span class="w">
</span><span class="w">
</span><span class="w"></span>- <span class="k">groups</span><span class="p">:</span><span class="w">
</span><span class="hl"><span class="w">  </span>- system<span class="p">:</span>bootstrappers<span class="p">:</span>kubeadm<span class="p">:</span>default-node-token<span class="w">
</span></span><span class="w">    </span><span class="k">token</span><span class="p">:</span><span class="w"> </span>d7cb0e.605fb37fed0895d3<span class="w"> </span><span class="c"># 使用命令 echo &#34;$(openssl rand -hex 3).$(openssl rand -hex 8)&#34; 生成</span><span class="w">
</span><span class="w">    </span><span class="k">ttl</span><span class="p">:</span><span class="w"> </span>24h0m0s<span class="w">
</span><span class="w">    </span><span class="k">usages</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- signing<span class="w">
</span><span class="w">  </span>- authentication<span class="w">
</span><span class="w">    </span><span class="k">kind</span><span class="p">:</span><span class="w"> </span>InitConfiguration<span class="w">
</span><span class="hl"><span class="w">    </span><span class="k">localAPIEndpoint</span><span class="p">:</span><span class="w">
</span></span><span class="w">    </span><span class="k">advertiseAddress</span><span class="p">:</span><span class="w"> </span><span class="m">10.64.144.100</span><span class="w"> </span><span class="c"># Master 节点的本机 IP 地址</span><span class="w">
</span><span class="w">    </span><span class="k">bindPort</span><span class="p">:</span><span class="w"> </span><span class="m">6443</span><span class="w">
</span><span class="w">    </span><span class="k">nodeRegistration</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="k">criSocket</span><span class="p">:</span><span class="w"> </span>/var/run/dockershim.sock<span class="w">
</span><span class="w">    </span><span class="k">name</span><span class="p">:</span><span class="w"> </span>k8s-master<span class="w">
</span><span class="w">    </span><span class="k">taints</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="k">effect</span><span class="p">:</span><span class="w"> </span>NoSchedule<span class="w">
</span><span class="w">    </span><span class="k">key</span><span class="p">:</span><span class="w"> </span>node-role.kubernetes.io/master<span class="w">
</span><span class="w">
</span><span class="w"></span>---<span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">apiServer</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="k">timeoutForControlPlane</span><span class="p">:</span><span class="w"> </span>4m0s<span class="w">
</span><span class="w"></span><span class="k">apiVersion</span><span class="p">:</span><span class="w"> </span>kubeadm.k8s.io/v1beta2<span class="w">
</span><span class="w"></span><span class="k">certificatesDir</span><span class="p">:</span><span class="w"> </span>/etc/kubernetes/pki<span class="w">
</span><span class="w"></span><span class="k">clusterName</span><span class="p">:</span><span class="w"> </span>kubernetes<span class="w">
</span><span class="w"></span><span class="k">controllerManager</span><span class="p">:</span><span class="w"> </span>{}<span class="w">
</span><span class="w"></span><span class="k">dns</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="k">type</span><span class="p">:</span><span class="w"> </span>CoreDNS<span class="w">
</span><span class="hl"><span class="w"></span><span class="k">etcd</span><span class="p">:</span><span class="w">
</span></span><span class="w"></span><span class="k">local</span><span class="p">:</span><span class="w">
</span><span class="hl"><span class="w"></span><span class="k">dataDir</span><span class="p">:</span><span class="w"> </span>/var/lib/etcd<span class="w">
</span></span><span class="w"></span><span class="k">imageRepository</span><span class="p">:</span><span class="w"> </span>registry.cn-hangzhou.aliyuncs.com/google_containers<span class="w"> </span><span class="c"># 由于默认的`k8s.gcr.io`在国内无法正常访问，这里使用阿里云的源代替</span><span class="w">
</span><span class="w"></span><span class="k">kind</span><span class="p">:</span><span class="w"> </span>ClusterConfiguration<span class="w">
</span><span class="hl"><span class="w"></span><span class="k">kubernetesVersion</span><span class="p">:</span><span class="w"> </span>v1<span class="m">.16.3</span><span class="w"> </span><span class="c"># kubernetes 版本</span><span class="w">
</span></span><span class="hl"><span class="w"></span><span class="k">networking</span><span class="p">:</span><span class="w">
</span></span><span class="w"></span><span class="k">dnsDomain</span><span class="p">:</span><span class="w"> </span>cluster.local<span class="w">
</span><span class="w"></span><span class="k">serviceSubnet</span><span class="p">:</span><span class="w"> </span><span class="m">10.96.0.0</span>/<span class="m">12</span><span class="w"> </span><span class="c"># 集群 service 的网段</span><span class="w">
</span><span class="w"></span><span class="k">podSubnet</span><span class="p">:</span><span class="w"> </span><span class="m">172.16.0.0</span>/<span class="m">16</span><span class="w"> </span><span class="c"># 集群 pod 网段</span><span class="w">
</span><span class="w"></span><span class="k">scheduler</span><span class="p">:</span><span class="w"> </span>{}<span class="w">
</span><span class="w">
</span><span class="w"></span>---<span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">apiVersion</span><span class="p">:</span><span class="w"> </span>kubeproxy.config.k8s.io/v1alpha1<span class="w">
</span><span class="w"></span><span class="k">bindAddress</span><span class="p">:</span><span class="w"> </span><span class="m">0.0.0.0</span><span class="w">
</span><span class="w"></span><span class="k">clientConnection</span><span class="p">:</span><span class="w">
</span><span class="hl"><span class="w"></span><span class="k">acceptContentTypes</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;&#34;</span><span class="w">
</span></span><span class="w"></span><span class="k">burst</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span><span class="w"></span><span class="k">contentType</span><span class="p">:</span><span class="w"> </span>application/vnd.kubernetes.protobuf<span class="w">
</span><span class="w"></span><span class="k">kubeconfig</span><span class="p">:</span><span class="w"> </span>/var/lib/kube-proxy/kubeconfig.conf<span class="w">
</span><span class="w"></span><span class="k">qps</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w"></span><span class="k">clusterCIDR</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;172.16.0.0/16&#34;</span><span class="w"> </span><span class="c"># 集群 pod 的网段，需要与后续部署的网络插件一致</span><span class="w">
</span><span class="w"></span><span class="k">configSyncPeriod</span><span class="p">:</span><span class="w"> </span>15m0s<span class="w">
</span><span class="w"></span><span class="k">conntrack</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="k">maxPerCore</span><span class="p">:</span><span class="w"> </span><span class="m">32768</span><span class="w">
</span><span class="w"></span><span class="k">min</span><span class="p">:</span><span class="w"> </span><span class="m">131072</span><span class="w">
</span><span class="w"></span><span class="k">tcpCloseWaitTimeout</span><span class="p">:</span><span class="w"> </span>1h0m0s<span class="w">
</span><span class="w"></span><span class="k">tcpEstablishedTimeout</span><span class="p">:</span><span class="w"> </span>24h0m0s<span class="w">
</span><span class="w"></span><span class="k">enableProfiling</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w"></span><span class="k">healthzBindAddress</span><span class="p">:</span><span class="w"> </span><span class="m">0.0.0.0</span><span class="p">:</span><span class="m">10256</span><span class="w">
</span><span class="w"></span><span class="k">hostnameOverride</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;&#34;</span><span class="w">
</span><span class="w"></span><span class="k">iptables</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="k">masqueradeAll</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w"></span><span class="k">masqueradeBit</span><span class="p">:</span><span class="w"> </span><span class="m">14</span><span class="w">
</span><span class="w"></span><span class="k">minSyncPeriod</span><span class="p">:</span><span class="w"> </span>0s<span class="w">
</span><span class="w"></span><span class="k">syncPeriod</span><span class="p">:</span><span class="w"> </span>30s<span class="w">
</span><span class="w"></span><span class="k">ipvs</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="k">excludeCIDRs</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="w">
</span><span class="w"></span><span class="k">minSyncPeriod</span><span class="p">:</span><span class="w"> </span>0s<span class="w">
</span><span class="hl"><span class="w"></span><span class="k">scheduler</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;&#34;</span><span class="w">
</span></span><span class="w"></span><span class="k">strictARP</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w"></span><span class="k">syncPeriod</span><span class="p">:</span><span class="w"> </span>30s<span class="w">
</span><span class="w"></span><span class="k">kind</span><span class="p">:</span><span class="w"> </span>KubeProxyConfiguration<span class="w">
</span><span class="w"></span><span class="k">metricsBindAddress</span><span class="p">:</span><span class="w"> </span><span class="m">0.0.0.0</span><span class="p">:</span><span class="m">10249</span><span class="w">
</span><span class="w"></span><span class="k">mode</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;ipvs&#34;</span><span class="w"> </span><span class="c"># Kube-Proxy 使用 ipvs 模式， 1.11 之后的版本默认使用 ipvs 代替了 iptables。如果节点上没有启用 ipvs 内核模块，会自动降级为 iptables</span><span class="w">
</span><span class="w"></span><span class="k">nodePortAddresses</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="w">
</span><span class="w"></span><span class="k">oomScoreAdj</span><span class="p">:</span><span class="w"> </span>-<span class="m">999</span><span class="w">
</span><span class="w"></span><span class="k">portRange</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;&#34;</span><span class="w">
</span><span class="w"></span><span class="k">udpIdleTimeout</span><span class="p">:</span><span class="w"> </span>250ms<span class="w">
</span><span class="w"></span><span class="k">winkernel</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="k">enableDSR</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w"></span><span class="k">networkName</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;&#34;</span><span class="w">
</span><span class="w"></span><span class="k">sourceVip</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;&#34;</span><span class="w">
</span><span class="w">
</span><span class="w"></span>---<span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">address</span><span class="p">:</span><span class="w"> </span><span class="m">0.0.0.0</span><span class="w">
</span><span class="w"></span><span class="k">apiVersion</span><span class="p">:</span><span class="w"> </span>kubelet.config.k8s.io/v1beta1<span class="w">
</span><span class="w"></span><span class="k">authentication</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="k">anonymous</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="k">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w"></span><span class="k">webhook</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="k">cacheTTL</span><span class="p">:</span><span class="w"> </span>2m0s<span class="w">
</span><span class="w"></span><span class="k">enabled</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="hl"><span class="w"></span><span class="k">x509</span><span class="p">:</span><span class="w">
</span></span><span class="hl"><span class="w"></span><span class="k">clientCAFile</span><span class="p">:</span><span class="w"> </span>/etc/kubernetes/pki/ca.crt<span class="w">
</span></span><span class="hl"><span class="w"></span><span class="k">authorization</span><span class="p">:</span><span class="w">
</span></span><span class="hl"><span class="w"></span><span class="k">mode</span><span class="p">:</span><span class="w"> </span>Webhook<span class="w">
</span></span><span class="w"></span><span class="k">webhook</span><span class="p">:</span><span class="w">
</span><span class="w"></span><span class="k">cacheAuthorizedTTL</span><span class="p">:</span><span class="w"> </span>5m0s<span class="w">
</span><span class="w"></span><span class="k">cacheUnauthorizedTTL</span><span class="p">:</span><span class="w"> </span>30s<span class="w">
</span><span class="w"></span><span class="k">cgroupDriver</span><span class="p">:</span><span class="w"> </span>systemd<span class="w"> </span><span class="c"># cgroup 管理方式，需要与 docker 中的`native.cgroupdriver`一致，推荐使用 systemd</span><span class="w">
</span><span class="w"></span><span class="k">cgroupsPerQOS</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w"></span><span class="k">clusterDNS</span><span class="p">:</span><span class="w">
</span><span class="w">
</span><span class="w"></span>- <span class="m">10.96.0.10</span><span class="w"> </span><span class="c"># 集群中 CoreDNS 的 Service IP 地址，需要在上面配置`networking.serviceSubnet`子网中</span><span class="w">
</span><span class="w">  </span><span class="k">clusterDomain</span><span class="p">:</span><span class="w"> </span>cluster.local<span class="w">
</span><span class="w">  </span><span class="k">configMapAndSecretChangeDetectionStrategy</span><span class="p">:</span><span class="w"> </span>Watch<span class="w">
</span><span class="w">  </span><span class="k">containerLogMaxFiles</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">  </span><span class="k">containerLogMaxSize</span><span class="p">:</span><span class="w"> </span>10Mi<span class="w">
</span><span class="w">  </span><span class="k">contentType</span><span class="p">:</span><span class="w"> </span>application/vnd.kubernetes.protobuf<span class="w">
</span><span class="w">  </span><span class="k">cpuCFSQuota</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="k">cpuCFSQuotaPeriod</span><span class="p">:</span><span class="w"> </span>100ms<span class="w">
</span><span class="w">  </span><span class="k">cpuManagerPolicy</span><span class="p">:</span><span class="w"> </span>none<span class="w">
</span><span class="w">  </span><span class="k">cpuManagerReconcilePeriod</span><span class="p">:</span><span class="w"> </span>10s<span class="w">
</span><span class="w">  </span><span class="k">enableControllerAttachDetach</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="k">enableDebuggingHandlers</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="k">enforceNodeAllocatable</span><span class="p">:</span><span class="w">
</span><span class="w"></span>- pods<span class="w">
</span><span class="w">  </span><span class="k">eventBurst</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span><span class="w">  </span><span class="k">eventRecordQPS</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">  </span><span class="k">evictionHard</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="k">imagefs.available</span><span class="p">:</span><span class="w"> </span><span class="m">15</span>%<span class="w">
</span><span class="w">  </span><span class="k">memory.available</span><span class="p">:</span><span class="w"> </span>100Mi<span class="w">
</span><span class="w">  </span><span class="k">nodefs.available</span><span class="p">:</span><span class="w"> </span><span class="m">10</span>%<span class="w">
</span><span class="w">  </span><span class="k">nodefs.inodesFree</span><span class="p">:</span><span class="w"> </span><span class="m">5</span>%<span class="w">
</span><span class="w">  </span><span class="k">evictionPressureTransitionPeriod</span><span class="p">:</span><span class="w"> </span>5m0s<span class="w">
</span><span class="w">  </span><span class="k">failSwapOn</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="k">fileCheckFrequency</span><span class="p">:</span><span class="w"> </span>20s<span class="w">
</span><span class="w">  </span><span class="k">hairpinMode</span><span class="p">:</span><span class="w"> </span>promiscuous-bridge<span class="w">
</span><span class="w">  </span><span class="k">healthzBindAddress</span><span class="p">:</span><span class="w"> </span><span class="m">127.0.0.1</span><span class="w">
</span><span class="w">  </span><span class="k">healthzPort</span><span class="p">:</span><span class="w"> </span><span class="m">10248</span><span class="w">
</span><span class="w">  </span><span class="k">httpCheckFrequency</span><span class="p">:</span><span class="w"> </span>20s<span class="w">
</span><span class="w">  </span><span class="k">imageGCHighThresholdPercent</span><span class="p">:</span><span class="w"> </span><span class="m">85</span><span class="w">
</span><span class="w">  </span><span class="k">imageGCLowThresholdPercent</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">
</span><span class="w">  </span><span class="k">imageMinimumGCAge</span><span class="p">:</span><span class="w"> </span>2m0s<span class="w">
</span><span class="w">  </span><span class="k">iptablesDropBit</span><span class="p">:</span><span class="w"> </span><span class="m">15</span><span class="w">
</span><span class="w">  </span><span class="k">iptablesMasqueradeBit</span><span class="p">:</span><span class="w"> </span><span class="m">14</span><span class="w">
</span><span class="w">  </span><span class="k">kind</span><span class="p">:</span><span class="w"> </span>KubeletConfiguration<span class="w">
</span><span class="w">  </span><span class="k">kubeAPIBurst</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span><span class="w">  </span><span class="k">kubeAPIQPS</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">  </span><span class="k">makeIPTablesUtilChains</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="k">maxOpenFiles</span><span class="p">:</span><span class="w"> </span><span class="m">1000000</span><span class="w">
</span><span class="w">  </span><span class="k">maxPods</span><span class="p">:</span><span class="w"> </span><span class="m">110</span><span class="w">
</span><span class="w">  </span><span class="k">nodeLeaseDurationSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">40</span><span class="w">
</span><span class="w">  </span><span class="k">nodeStatusReportFrequency</span><span class="p">:</span><span class="w"> </span>1m0s<span class="w">
</span><span class="w">  </span><span class="k">nodeStatusUpdateFrequency</span><span class="p">:</span><span class="w"> </span>10s<span class="w">
</span><span class="w">  </span><span class="k">oomScoreAdj</span><span class="p">:</span><span class="w"> </span>-<span class="m">999</span><span class="w">
</span><span class="w">  </span><span class="k">podPidsLimit</span><span class="p">:</span><span class="w"> </span>-<span class="m">1</span><span class="w">
</span><span class="w">  </span><span class="k">port</span><span class="p">:</span><span class="w"> </span><span class="m">10250</span><span class="w">
</span><span class="w">  </span><span class="k">registryBurst</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span><span class="w">  </span><span class="k">registryPullQPS</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">  </span><span class="k">resolvConf</span><span class="p">:</span><span class="w"> </span>/etc/resolv.conf<span class="w">
</span><span class="w">  </span><span class="k">rotateCertificates</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="k">runtimeRequestTimeout</span><span class="p">:</span><span class="w"> </span>2m0s<span class="w">
</span><span class="w">  </span><span class="k">serializeImagePulls</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">  </span><span class="k">staticPodPath</span><span class="p">:</span><span class="w"> </span>/etc/kubernetes/manifests<span class="w">
</span><span class="w">  </span><span class="k">streamingConnectionIdleTimeout</span><span class="p">:</span><span class="w"> </span>4h0m0s<span class="w">
</span><span class="w">  </span><span class="k">syncFrequency</span><span class="p">:</span><span class="w"> </span>1m0s<span class="w">
</span><span class="w">  </span><span class="k">topologyManagerPolicy</span><span class="p">:</span><span class="w"> </span>none<span class="w">
</span><span class="w">  </span><span class="k">volumeStatsAggPeriod</span><span class="p">:</span><span class="w"> </span>1m0s<span class="w">
</span><span class="w">  </span></code></pre></td></tr></table>
</div>
</div>
<h3 id="下载所需镜像可选">下载所需镜像(可选)</h3>
<p>初始化的时候也会自动下载所有的镜像,提前下载好镜像可减少后续初始化时的等待时间</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ kubeadm config images list --config kubeadm-config.yaml <span class="c1"># 查看镜像列表</span>
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.16.3
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.16.3
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.16.3
registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.3
registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1
registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.15-0
registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.2
$ kubeadm config images pull --config kubeadm-config.yaml <span class="c1"># 下载镜像</span>
<span class="o">[</span>config/images<span class="o">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.16.3
<span class="o">[</span>config/images<span class="o">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.16.3
<span class="o">[</span>config/images<span class="o">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.16.3
<span class="o">[</span>config/images<span class="o">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.16.3
<span class="o">[</span>config/images<span class="o">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.1
<span class="o">[</span>config/images<span class="o">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.3.15-0
<span class="o">[</span>config/images<span class="o">]</span> Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:1.6.2
</code></pre></td></tr></table>
</div>
</div><h3 id="初始化">初始化</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ kubeadm init --config kubeadm-config.yaml
<span class="o">[</span>init<span class="o">]</span> Using Kubernetes version: v1.16.3
<span class="o">[</span>preflight<span class="o">]</span> Running pre-flight checks
<span class="o">[</span>preflight<span class="o">]</span> Pulling images required <span class="k">for</span> setting up a Kubernetes cluster
<span class="o">[</span>preflight<span class="o">]</span> This might take a minute or two, depending on the speed of your internet connection
<span class="o">[</span>preflight<span class="o">]</span> You can also perform this action in beforehand using <span class="s1">&#39;kubeadm config images pull&#39;</span>
<span class="o">[</span>kubelet-start<span class="o">]</span> Writing kubelet environment file with flags to file <span class="s2">&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
<span class="o">[</span>kubelet-start<span class="o">]</span> Writing kubelet configuration to file <span class="s2">&#34;/var/lib/kubelet/config.yaml&#34;</span>
<span class="o">[</span>kubelet-start<span class="o">]</span> Activating the kubelet service
<span class="o">[</span>certs<span class="o">]</span> Using certificateDir folder <span class="s2">&#34;/etc/kubernetes/pki&#34;</span>
<span class="o">[</span>certs<span class="o">]</span> Generating <span class="s2">&#34;ca&#34;</span> certificate and key
<span class="o">[</span>certs<span class="o">]</span> Generating <span class="s2">&#34;apiserver&#34;</span> certificate and key
<span class="o">[</span>certs<span class="o">]</span> apiserver serving cert is signed <span class="k">for</span> DNS names <span class="o">[</span>k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local<span class="o">]</span> and IPs <span class="o">[</span>10.96.0.1 10.64.144.100<span class="o">]</span>
<span class="o">[</span>certs<span class="o">]</span> Generating <span class="s2">&#34;apiserver-kubelet-client&#34;</span> certificate and key
<span class="o">[</span>certs<span class="o">]</span> Generating <span class="s2">&#34;front-proxy-ca&#34;</span> certificate and key
<span class="o">[</span>certs<span class="o">]</span> Generating <span class="s2">&#34;front-proxy-client&#34;</span> certificate and key
<span class="o">[</span>certs<span class="o">]</span> Generating <span class="s2">&#34;etcd/ca&#34;</span> certificate and key
<span class="o">[</span>certs<span class="o">]</span> Generating <span class="s2">&#34;etcd/server&#34;</span> certificate and key
<span class="o">[</span>certs<span class="o">]</span> etcd/server serving cert is signed <span class="k">for</span> DNS names <span class="o">[</span>k8s-master localhost<span class="o">]</span> and IPs <span class="o">[</span>10.64.144.100 127.0.0.1 ::1<span class="o">]</span>
<span class="o">[</span>certs<span class="o">]</span> Generating <span class="s2">&#34;etcd/peer&#34;</span> certificate and key
<span class="o">[</span>certs<span class="o">]</span> etcd/peer serving cert is signed <span class="k">for</span> DNS names <span class="o">[</span>k8s-master localhost<span class="o">]</span> and IPs <span class="o">[</span>10.64.144.100 127.0.0.1 ::1<span class="o">]</span>
<span class="o">[</span>certs<span class="o">]</span> Generating <span class="s2">&#34;etcd/healthcheck-client&#34;</span> certificate and key
<span class="o">[</span>certs<span class="o">]</span> Generating <span class="s2">&#34;apiserver-etcd-client&#34;</span> certificate and key
<span class="o">[</span>certs<span class="o">]</span> Generating <span class="s2">&#34;sa&#34;</span> key and public key
<span class="o">[</span>kubeconfig<span class="o">]</span> Using kubeconfig folder <span class="s2">&#34;/etc/kubernetes&#34;</span>
<span class="o">[</span>kubeconfig<span class="o">]</span> Writing <span class="s2">&#34;admin.conf&#34;</span> kubeconfig file
<span class="o">[</span>kubeconfig<span class="o">]</span> Writing <span class="s2">&#34;kubelet.conf&#34;</span> kubeconfig file
<span class="o">[</span>kubeconfig<span class="o">]</span> Writing <span class="s2">&#34;controller-manager.conf&#34;</span> kubeconfig file
<span class="o">[</span>kubeconfig<span class="o">]</span> Writing <span class="s2">&#34;scheduler.conf&#34;</span> kubeconfig file
<span class="o">[</span>control-plane<span class="o">]</span> Using manifest folder <span class="s2">&#34;/etc/kubernetes/manifests&#34;</span>
<span class="o">[</span>control-plane<span class="o">]</span> Creating static Pod manifest <span class="k">for</span> <span class="s2">&#34;kube-apiserver&#34;</span>
<span class="o">[</span>control-plane<span class="o">]</span> Creating static Pod manifest <span class="k">for</span> <span class="s2">&#34;kube-controller-manager&#34;</span>
<span class="o">[</span>control-plane<span class="o">]</span> Creating static Pod manifest <span class="k">for</span> <span class="s2">&#34;kube-scheduler&#34;</span>
<span class="o">[</span>etcd<span class="o">]</span> Creating static Pod manifest <span class="k">for</span> <span class="nb">local</span> etcd in <span class="s2">&#34;/etc/kubernetes/manifests&#34;</span>
<span class="o">[</span>wait-control-plane<span class="o">]</span> Waiting <span class="k">for</span> the kubelet to boot up the control plane as static Pods from directory <span class="s2">&#34;/etc/kubernetes/manifests&#34;</span>. This can take up to 4m0s
<span class="o">[</span>apiclient<span class="o">]</span> All control plane components are healthy after 34.001666 seconds
<span class="o">[</span>upload-config<span class="o">]</span> Storing the configuration used in ConfigMap <span class="s2">&#34;kubeadm-config&#34;</span> in the <span class="s2">&#34;kube-system&#34;</span> Namespace
<span class="o">[</span>kubelet<span class="o">]</span> Creating a ConfigMap <span class="s2">&#34;kubelet-config-1.16&#34;</span> in namespace kube-system with the configuration <span class="k">for</span> the kubelets in the cluster
<span class="o">[</span>upload-certs<span class="o">]</span> Skipping phase. Please see --upload-certs
<span class="o">[</span>mark-control-plane<span class="o">]</span> Marking the node k8s-master as control-plane by adding the label <span class="s2">&#34;node-role.kubernetes.io/master=&#39;&#39;&#34;</span>
<span class="o">[</span>mark-control-plane<span class="o">]</span> Marking the node k8s-master as control-plane by adding the taints <span class="o">[</span>node-role.kubernetes.io/master:NoSchedule<span class="o">]</span>
<span class="o">[</span>bootstrap-token<span class="o">]</span> Using token: d7cb0e.605fb37fed0895d3
<span class="o">[</span>bootstrap-token<span class="o">]</span> Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
<span class="o">[</span>bootstrap-token<span class="o">]</span> configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order <span class="k">for</span> nodes to get long term certificate credentials
<span class="o">[</span>bootstrap-token<span class="o">]</span> configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
<span class="o">[</span>bootstrap-token<span class="o">]</span> configured RBAC rules to allow certificate rotation <span class="k">for</span> all node client certificates in the cluster
<span class="o">[</span>bootstrap-token<span class="o">]</span> Creating the <span class="s2">&#34;cluster-info&#34;</span> ConfigMap in the <span class="s2">&#34;kube-public&#34;</span> namespace
<span class="o">[</span>addons<span class="o">]</span> Applied essential addon: CoreDNS
<span class="o">[</span>addons<span class="o">]</span> Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p <span class="nv">$HOME</span>/.kube
  sudo cp -i /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config
  sudo chown <span class="k">$(</span>id -u<span class="k">)</span>:<span class="k">$(</span>id -g<span class="k">)</span> <span class="nv">$HOME</span>/.kube/config

You should now deploy a pod network to the cluster.
Run <span class="s2">&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 10.64.144.100:6443 --token d7cb0e.605fb37fed0895d3 <span class="se">\
</span><span class="se"></span>    --discovery-token-ca-cert-hash sha256:dcabbe4b86492eb5da1f22c2a24fb1b5698557185abd481d858eda25a8d926aa
</code></pre></td></tr></table>
</div>
</div><p>如上提示有三条信息</p>
<ul>
<li>需要配置 kubeconfig ,以便 kubectl 可以操作集群</li>
<li>需要选择一个网络插件进行安装，以使集群可以连接网络通信</li>
<li>保存最后一条命令，后续 worker 节点加入集群时会用到</li>
</ul>
<h3 id="配置-kubeconfig">配置 kubeconfig</h3>
<p>按上面提示操作就行</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">mkdir -p <span class="nv">$HOME</span>/.kube
sudo cp -i /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config
sudo chown <span class="k">$(</span>id -u<span class="k">)</span>:<span class="k">$(</span>id -g<span class="k">)</span> <span class="nv">$HOME</span>/.kube/config
</code></pre></td></tr></table>
</div>
</div><p>使用 kubectl 查看集群当前状态，顺便检验 kubeconfig 是否配置正确</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ kubectl get pods -n kube-system <span class="c1"># 查看系统组件运行状态</span>
NAME                                 READY   STATUS    RESTARTS   AGE
coredns-67c766df46-5d5pp             0/1     Pending   <span class="m">0</span>          4m40s
coredns-67c766df46-kjd9f             0/1     Pending   <span class="m">0</span>          4m40s
etcd-k8s-master                      1/1     Running   <span class="m">0</span>          3m34s
kube-apiserver-k8s-master            1/1     Running   <span class="m">0</span>          3m41s
kube-controller-manager-k8s-master   1/1     Running   <span class="m">0</span>          3m44s
kube-proxy-r2w74                     1/1     Running   <span class="m">0</span>          4m39s
kube-scheduler-k8s-master            1/1     Running   <span class="m">0</span>          3m44s
$ kubectl get nodes  <span class="c1"># 查看节点状态</span>
NAME         STATUS     ROLES    AGE    VERSION
k8s-master   NotReady   master   5m6s   v1.16.3
</code></pre></td></tr></table>
</div>
</div><p>以上两个 coredns 的 pod 处于 Pending 状态，以及 master 节点 NotReady 状态，是由于我们集群中还没有安装可通信的网络插件，暂时先忽略即可</p>
<h2 id="加入-worker-节点到集群">加入 worker 节点到集群</h2>
<blockquote>
<p>在 woker 节点上操作</p>
</blockquote>
<p>还记得<code>kubeadm init</code>后输出的最后一条命令吗，worker 节点上只需要执行这一条命令就行了</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ kubeadm join 10.64.144.100:6443 --token d7cb0e.605fb37fed0895d3 --discovery-token-ca-cert-hash sha256:dcabbe4b86492eb5da1f22c2a24fb1b5698557185abd481d858eda25a8d926aa
<span class="o">[</span>preflight<span class="o">]</span> Running pre-flight checks
<span class="o">[</span>preflight<span class="o">]</span> Reading configuration from the cluster...
<span class="o">[</span>preflight<span class="o">]</span> FYI: You can look at this config file with <span class="s1">&#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;</span>
<span class="o">[</span>kubelet-start<span class="o">]</span> Downloading configuration <span class="k">for</span> the kubelet from the <span class="s2">&#34;kubelet-config-1.16&#34;</span> ConfigMap in the kube-system namespace
<span class="o">[</span>kubelet-start<span class="o">]</span> Writing kubelet configuration to file <span class="s2">&#34;/var/lib/kubelet/config.yaml&#34;</span>
<span class="o">[</span>kubelet-start<span class="o">]</span> Writing kubelet environment file with flags to file <span class="s2">&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
<span class="o">[</span>kubelet-start<span class="o">]</span> Activating the kubelet service
<span class="o">[</span>kubelet-start<span class="o">]</span> Waiting <span class="k">for</span> the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run <span class="s1">&#39;kubectl get nodes&#39;</span> on the control-plane to see this node join the cluster.
</code></pre></td></tr></table>
</div>
</div><blockquote>
<p>master 节点上操作</p>
</blockquote>
<p>所有节点上都执行后，在 master 上查看节点状态</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ kubectl get nodes
NAME         STATUS     ROLES    AGE   VERSION
k8s-master   NotReady   master   18m   v1.16.3
k8s-node01   NotReady   &lt;none&gt;   57s   v1.16.3
k8s-node02   NotReady   &lt;none&gt;   20s   v1.16.3
k8s-node03   NotReady   &lt;none&gt;   9s    v1.16.3
k8s-node04   NotReady   &lt;none&gt;   2s    v1.16.3
k8s-node05   NotReady   &lt;none&gt;   2s    v1.16.3
k8s-node06   NotReady   &lt;none&gt;   2s    v1.16.3
</code></pre></td></tr></table>
</div>
</div><p>到目前为止，我们集群已经创建好的，但是节点间还不能相互通信，所以状态都还是<code>NotReady</code></p>
<p>接下来我们将选择一款适合自己的网络插件来部署</p>
<h2 id="安装-cni-网络插件">安装 CNI 网络插件</h2>
<blockquote>
<p>所有操作均在 master 节点上</p>
</blockquote>
<p>注意事项及支持的网络插件列表请参考官网 <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network" target="_blank" rel="noopener noreffer">Installing a pod network add-on</a> 及 <a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/#networking-and-network-policy" target="_blank" rel="noopener noreffer">Networking and Network Policy</a></p>
<p>关于各 CNI 插件的功能对比可以参考 <a href="https://blog.csdn.net/RancherLabs/article/details/88885539" target="_blank" rel="noopener noreffer">Kubernetes CNI 网络最强对比：Flannel、Calico、Canal 和 Weave</a> 和性能基准测试 <a href="https://zhuanlan.zhihu.com/p/53296042" target="_blank" rel="noopener noreffer">K8S 网络插件（CNI）超过 10Gbit/s 的基准测试结果</a></p>
<p>由于我们实验环境是二层可达，所以选用 Calico BGP 模式，如果二层不可达，可以考虑使用 Calico IPIP 或者 Flannel VXLAN</p>
<h3 id="下载-calicoyaml">下载 calico.yaml</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">curl -O https://docs.projectcalico.org/manifests/calico.yaml
</code></pre></td></tr></table>
</div>
</div><p>默认情况下，不做修改也可以，calico 会自动发现 cluster cidr, 这里我们自行修改下</p>
<p>主要改动如下:</p>
<ul>
<li><code>CALICO_IPV4POOL_IPIP</code> 设置为 <code>Never</code>，关闭 IPIP 模式</li>
<li><code>CALICO_IPV4POOL_CIDR</code> 设置为 <code>172.16.0.0/16</code>，对应 kubeadm 中的 <code>cluster-cidr</code></li>
</ul>
<h3 id="部署">部署</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ kubectl apply -f caclico.yml
</code></pre></td></tr></table>
</div>
</div><h3 id="通过-calicoctl-查看-bgp-节点状态">通过 calicoctl 查看 BGP 节点状态</h3>
<p>calicoctl 可以支持通过直接操作 <code>etcd</code> 或者对接 kubernetes apiserver 两种数据源，我这里使用 kubernetes 方式</p>
<p>具体的安装及配置方式请参考官网 <a href="https://docs.projectcalico.org/getting-started/clis/calicoctl/install" target="_blank" rel="noopener noreffer">Install calicoctl</a> 与 <a href="https://docs.projectcalico.org/getting-started/clis/calicoctl/configure/overview" target="_blank" rel="noopener noreffer">Configure calicoctl</a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ <span class="nb">export</span> <span class="nv">CALICO_DATASTORE_TYPE</span><span class="o">=</span>kubernetes
$ <span class="nb">export</span> <span class="nv">CALICO_KUBECONFIG</span><span class="o">=</span>/etc/kubernetes/admin.conf
$ calicoctl node status
Calico process is running.

IPv4 BGP status
+---------------+-------------------+-------+----------+-------------+
<span class="p">|</span> PEER ADDRESS  <span class="p">|</span>     PEER TYPE     <span class="p">|</span> STATE <span class="p">|</span>  SINCE   <span class="p">|</span>    INFO     <span class="p">|</span>
+---------------+-------------------+-------+----------+-------------+
<span class="p">|</span> 10.64.144.101 <span class="p">|</span> node-to-node mesh <span class="p">|</span> up    <span class="p">|</span> 18:11:48 <span class="p">|</span> Established <span class="p">|</span>
<span class="p">|</span> 10.64.144.102 <span class="p">|</span> node-to-node mesh <span class="p">|</span> up    <span class="p">|</span> 18:10:48 <span class="p">|</span> Established <span class="p">|</span>
<span class="p">|</span> 10.64.144.103 <span class="p">|</span> node-to-node mesh <span class="p">|</span> up    <span class="p">|</span> 18:08:10 <span class="p">|</span> Established <span class="p">|</span>
<span class="p">|</span> 10.64.144.104 <span class="p">|</span> node-to-node mesh <span class="p">|</span> up    <span class="p">|</span> 18:22:31 <span class="p">|</span> Established <span class="p">|</span>
<span class="p">|</span> 10.64.144.105 <span class="p">|</span> node-to-node mesh <span class="p">|</span> up    <span class="p">|</span> 18:22:31 <span class="p">|</span> Established <span class="p">|</span>
<span class="p">|</span> 10.64.144.106 <span class="p">|</span> node-to-node mesh <span class="p">|</span> up    <span class="p">|</span> 18:07:43 <span class="p">|</span> Established <span class="p">|</span>
+---------------+-------------------+-------+----------+-------------+

IPv6 BGP status
No IPv6 peers found.
</code></pre></td></tr></table>
</div>
</div><h3 id="确认查看集群状态">确认查看集群状态</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ kubectl get pods -n kube-system
NAME                                       READY   STATUS    RESTARTS   AGE
calico-kube-controllers-7d4d547dd6-qr98t   1/1     Running   <span class="m">0</span>          22s
calico-node-8d8bm                          1/1     Running   <span class="m">0</span>          22s
calico-node-hlv2h                          1/1     Running   <span class="m">0</span>          22s
calico-node-nbt4b                          1/1     Running   <span class="m">0</span>          22s
calico-node-p4s45                          1/1     Running   <span class="m">0</span>          22s
calico-node-srb88                          1/1     Running   <span class="m">0</span>          22s
calico-node-vfpfv                          1/1     Running   <span class="m">0</span>          22s
coredns-67c766df46-5d5pp                   1/1     Running   <span class="m">0</span>          15m
coredns-67c766df46-kjd9f                   1/1     Running   <span class="m">0</span>          15m
etcd-k8s-master                            1/1     Running   <span class="m">0</span>          15m
kube-apiserver-k8s-master                  1/1     Running   <span class="m">0</span>          14m
kube-controller-manager-k8s-master         1/1     Running   <span class="m">0</span>          15m
kube-proxy-5tx57                           1/1     Running   <span class="m">0</span>          14m
kube-proxy-6zvzv                           1/1     Running   <span class="m">0</span>          14m
kube-proxy-hv8zt                           1/1     Running   <span class="m">0</span>          14m
kube-proxy-rfsjl                           1/1     Running   <span class="m">0</span>          14m
kube-proxy-tm7jz                           1/1     Running   <span class="m">0</span>          15m
kube-proxy-kkssc                           1/1     Running   <span class="m">0</span>          13m
kube-scheduler-k8s-master                  1/1     Running   <span class="m">0</span>          14m
$ kubectl get nodes
NAME         STATUS   ROLES    AGE   VERSION
k8s-master   Ready    master   16m   v1.16.3
k8s-node01   Ready    &lt;none&gt;   14m   v1.16.3
k8s-node02   Ready    &lt;none&gt;   14m   v1.16.3
k8s-node03   Ready    &lt;none&gt;   14m   v1.16.3
k8s-node04   Ready    &lt;none&gt;   14m   v1.16.3
k8s-node05   Ready    &lt;none&gt;   15m   v1.16.3
k8s-node06   Ready    &lt;none&gt;   14m   v1.16.3
</code></pre></td></tr></table>
</div>
</div><p>此时可以发现所有节点已经是 Ready 状态，且 coredns 也已经正常 Running</p>
<h2 id="配置节点之间流量加密-可选">配置节点之间流量加密 (可选)</h2>
<blockquote>
<p>所有节点上操作</p>
</blockquote>
<p>calico 支持通过 <code>WireGuard</code> 对节点之间的流量进行加密传输(仅支持 BGP 模式)</p>
<blockquote>
<p>目前处于 preview 状态，不可用于生产环境</p>
</blockquote>
<p>安装 WireGuard 可参考 <a href="https://www.wireguard.com/install/" target="_blank" rel="noopener noreffer">WireGuard Installation</a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ yum install epel-release https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm
$ yum install yum-plugin-elrepo
$ yum install kmod-wireguard wireguard-tools
</code></pre></td></tr></table>
</div>
</div><p>加载 WireGuard 内核模块</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ modprobe wireguard
$ lsmod <span class="p">|</span> grep wireguard
wireguard              <span class="m">86016</span>  <span class="m">0</span>
curve25519_x86_64      <span class="m">40960</span>  <span class="m">1</span> wireguard
libchacha20poly1305    <span class="m">16384</span>  <span class="m">1</span> wireguard
ip6_udp_tunnel         <span class="m">16384</span>  <span class="m">1</span> wireguard
udp_tunnel             <span class="m">16384</span>  <span class="m">1</span> wireguard
libblake2s             <span class="m">16384</span>  <span class="m">1</span> wireguard
libcurve25519_generic    <span class="m">53248</span>  <span class="m">2</span> curve25519_x86_64,wireguard
</code></pre></td></tr></table>
</div>
</div><p>添加模块开机自动加载</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ cat &gt; /etc/sysconfig/modules/wireguard.modules <span class="s">&lt;&lt;&#39;EOF&#39;
</span><span class="s">#!/bin/bash
</span><span class="s">/sbin/modinfo -F filename wireguard &gt; /dev/null 2&gt;&amp;1
</span><span class="s">if [ $? -eq 0 ]; then
</span><span class="s">    /sbin/modprobe wireguard
</span><span class="s">fi
</span><span class="s">EOF</span>
$ chmod +x wireguard.modules
</code></pre></td></tr></table>
</div>
</div><p>修改配置开启 wireguard 功能</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ calicoctl patch felixconfiguration default --type<span class="o">=</span><span class="s1">&#39;merge&#39;</span> -p <span class="s1">&#39;{&#34;spec&#34;:{&#34;wireguardEnabled&#34;:true}}&#39;</span>
Successfully patched <span class="m">1</span> <span class="s1">&#39;FelixConfiguration&#39;</span> resource
</code></pre></td></tr></table>
</div>
</div><p>查看节点状态</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ calicoctl get node k8s-master -oyaml
apiVersion: projectcalico.org/v3
kind: Node
....
status:
  wireguardPublicKey: 1OP5d3RVhBK7FE9tJ6l+eG38isdiy3LHzfqPzBSwI34<span class="o">=</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="测试">测试</h2>
<h3 id="创建-pod-测试集群是否能正常工作">创建 pod 测试集群是否能正常工作</h3>
<p>尝试创建名为 busybox 的 pod</p>
<blockquote>
<p>由于 1.28 以上版本的 busybox 镜像，使用 nslookup 的时候有些 bug 导致不能解析域名，此处使用官方提供提供的 1.28 版本 busybox 的 pod 配置</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/admin/dns/busybox.yaml
pod/busybox created
</code></pre></td></tr></table>
</div>
</div><h3 id="测试-coredns-能否正常工作">测试 coredns 能否正常工作</h3>
<p>在 busybox pod 中测试</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ kubectl <span class="nb">exec</span> -it busybox -- nslookup kubernetes.default.svc.cluster.local
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

Name:      kubernetes.default.svc.cluster.local
Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local
</code></pre></td></tr></table>
</div>
</div><p>在节点中使用 dig 命令测试</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ dig kubernetes.default.svc.cluster.local @10.96.0.10
<span class="p">;</span> &lt;&lt;&gt;&gt; DiG 9.11.4-P2-RedHat-9.11.4-9.P2.el7 &lt;&lt;&gt;&gt; kubernetes.default.svc.cluster.local @10.96.0.10
<span class="p">;;</span> global options: +cmd
<span class="p">;;</span> Got answer:
<span class="p">;;</span> WARNING: .local is reserved <span class="k">for</span> Multicast DNS
<span class="p">;;</span> You are currently testing what happens when an mDNS query is leaked to DNS
<span class="p">;;</span> -&gt;&gt;HEADER<span class="s">&lt;&lt;- opco</span>de: QUERY, status: NOERROR, id: <span class="m">56913</span>
<span class="p">;;</span> flags: qr aa rd<span class="p">;</span> QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: <span class="m">1</span>
<span class="p">;;</span> WARNING: recursion requested but not available

<span class="p">;;</span> OPT PSEUDOSECTION:
<span class="p">;</span> EDNS: version: 0, flags:<span class="p">;</span> udp: <span class="m">4096</span>
<span class="p">;;</span> QUESTION SECTION:
<span class="p">;</span>kubernetes.default.svc.cluster.local. IN A

<span class="p">;;</span> ANSWER SECTION:
kubernetes.default.svc.cluster.local. <span class="m">14</span> IN A   10.96.0.1

<span class="p">;;</span> Query time: <span class="m">1</span> msec
<span class="p">;;</span> SERVER: 10.96.0.10#53<span class="o">(</span>10.96.0.10<span class="o">)</span>
<span class="p">;;</span> WHEN: Fri Nov <span class="m">22</span> 12:21:58 CST <span class="m">2019</span>
<span class="p">;;</span> MSG SIZE  rcvd: <span class="m">117</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="安装-ingress">安装 Ingress</h2>
<p>配置文件参考官方 <a href="https://github.com/kubernetes/ingress-nginx/blob/master/deploy/static/mandatory.yaml" target="_blank" rel="noopener noreffer">mandatory.yaml</a></p>
<p>不过官方是使用 <code>Deployment</code> 来部署的，我这里改成了 <code>DaemonSet</code> 方式，同时补上了 <code>Service</code> 的部分</p>
<p>完整配置如下</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span><span class="lnt">176
</span><span class="lnt">177
</span><span class="lnt">178
</span><span class="lnt">179
</span><span class="lnt">180
</span><span class="lnt">181
</span><span class="lnt">182
</span><span class="lnt">183
</span><span class="lnt">184
</span><span class="lnt">185
</span><span class="lnt">186
</span><span class="lnt">187
</span><span class="lnt">188
</span><span class="lnt">189
</span><span class="lnt">190
</span><span class="lnt">191
</span><span class="lnt">192
</span><span class="lnt">193
</span><span class="lnt">194
</span><span class="lnt">195
</span><span class="lnt">196
</span><span class="lnt">197
</span><span class="lnt">198
</span><span class="lnt">199
</span><span class="lnt">200
</span><span class="lnt">201
</span><span class="lnt">202
</span><span class="lnt">203
</span><span class="lnt">204
</span><span class="lnt">205
</span><span class="lnt">206
</span><span class="lnt">207
</span><span class="lnt">208
</span><span class="lnt">209
</span><span class="lnt">210
</span><span class="lnt">211
</span><span class="lnt">212
</span><span class="lnt">213
</span><span class="lnt">214
</span><span class="lnt">215
</span><span class="lnt">216
</span><span class="lnt">217
</span><span class="lnt">218
</span><span class="lnt">219
</span><span class="lnt">220
</span><span class="lnt">221
</span><span class="lnt">222
</span><span class="lnt">223
</span><span class="lnt">224
</span><span class="lnt">225
</span><span class="lnt">226
</span><span class="lnt">227
</span><span class="lnt">228
</span><span class="lnt">229
</span><span class="lnt">230
</span><span class="lnt">231
</span><span class="lnt">232
</span><span class="lnt">233
</span><span class="lnt">234
</span><span class="lnt">235
</span><span class="lnt">236
</span><span class="lnt">237
</span><span class="lnt">238
</span><span class="lnt">239
</span><span class="lnt">240
</span><span class="lnt">241
</span><span class="lnt">242
</span><span class="lnt">243
</span><span class="lnt">244
</span><span class="lnt">245
</span><span class="lnt">246
</span><span class="lnt">247
</span><span class="lnt">248
</span><span class="lnt">249
</span><span class="lnt">250
</span><span class="lnt">251
</span><span class="lnt">252
</span><span class="lnt">253
</span><span class="lnt">254
</span><span class="lnt">255
</span><span class="lnt">256
</span><span class="lnt">257
</span><span class="lnt">258
</span><span class="lnt">259
</span><span class="lnt">260
</span><span class="lnt">261
</span><span class="lnt">262
</span><span class="lnt">263
</span><span class="lnt">264
</span><span class="lnt">265
</span><span class="lnt">266
</span><span class="lnt">267
</span><span class="lnt">268
</span><span class="lnt">269
</span><span class="lnt">270
</span><span class="lnt">271
</span><span class="lnt">272
</span><span class="lnt">273
</span><span class="lnt">274
</span><span class="lnt">275
</span><span class="lnt">276
</span><span class="lnt">277
</span><span class="lnt">278
</span><span class="lnt">279
</span><span class="lnt">280
</span><span class="lnt">281
</span><span class="lnt">282
</span><span class="lnt">283
</span><span class="lnt">284
</span><span class="lnt">285
</span><span class="lnt">286
</span><span class="lnt">287
</span><span class="lnt">288
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ cat &gt; ingress-nginx.yaml <span class="s">&lt;&lt;&#39;EOF&#39;
</span><span class="s">apiVersion: v1
</span><span class="s">kind: Namespace
</span><span class="s">metadata:
</span><span class="s">  name: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">---
</span><span class="s">kind: ConfigMap
</span><span class="s">apiVersion: v1
</span><span class="s">metadata:
</span><span class="s">  name: nginx-configuration
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">---
</span><span class="s">kind: ConfigMap
</span><span class="s">apiVersion: v1
</span><span class="s">metadata:
</span><span class="s">  name: tcp-services
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">---
</span><span class="s">kind: ConfigMap
</span><span class="s">apiVersion: v1
</span><span class="s">metadata:
</span><span class="s">  name: udp-services
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">---
</span><span class="s">apiVersion: v1
</span><span class="s">kind: ServiceAccount
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-serviceaccount
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">---
</span><span class="s">apiVersion: rbac.authorization.k8s.io/v1beta1
</span><span class="s">kind: ClusterRole
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-clusterrole
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">rules:
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - configmaps
</span><span class="s">      - endpoints
</span><span class="s">      - nodes
</span><span class="s">      - pods
</span><span class="s">      - secrets
</span><span class="s">    verbs:
</span><span class="s">      - list
</span><span class="s">      - watch
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - nodes
</span><span class="s">    verbs:
</span><span class="s">      - get
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - services
</span><span class="s">    verbs:
</span><span class="s">      - get
</span><span class="s">      - list
</span><span class="s">      - watch
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - events
</span><span class="s">    verbs:
</span><span class="s">      - create
</span><span class="s">      - patch
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;extensions&#34;
</span><span class="s">      - &#34;networking.k8s.io&#34;
</span><span class="s">    resources:
</span><span class="s">      - ingresses
</span><span class="s">    verbs:
</span><span class="s">      - get
</span><span class="s">      - list
</span><span class="s">      - watch
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;extensions&#34;
</span><span class="s">      - &#34;networking.k8s.io&#34;
</span><span class="s">    resources:
</span><span class="s">      - ingresses/status
</span><span class="s">    verbs:
</span><span class="s">      - update
</span><span class="s">---
</span><span class="s">apiVersion: rbac.authorization.k8s.io/v1beta1
</span><span class="s">kind: Role
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-role
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">rules:
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - configmaps
</span><span class="s">      - pods
</span><span class="s">      - secrets
</span><span class="s">      - namespaces
</span><span class="s">    verbs:
</span><span class="s">      - get
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - configmaps
</span><span class="s">    resourceNames:
</span><span class="s">      # Defaults to &#34;&lt;election-id&gt;-&lt;ingress-class&gt;&#34;
</span><span class="s">      # Here: &#34;&lt;ingress-controller-leader&gt;-&lt;nginx&gt;&#34;
</span><span class="s">      # This has to be adapted if you change either parameter
</span><span class="s">      # when launching the nginx-ingress-controller.
</span><span class="s">      - &#34;ingress-controller-leader-nginx&#34;
</span><span class="s">    verbs:
</span><span class="s">      - get
</span><span class="s">      - update
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - configmaps
</span><span class="s">    verbs:
</span><span class="s">      - create
</span><span class="s">  - apiGroups:
</span><span class="s">      - &#34;&#34;
</span><span class="s">    resources:
</span><span class="s">      - endpoints
</span><span class="s">    verbs:
</span><span class="s">      - get
</span><span class="s">---
</span><span class="s">apiVersion: rbac.authorization.k8s.io/v1beta1
</span><span class="s">kind: RoleBinding
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-role-nisa-binding
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">roleRef:
</span><span class="s">  apiGroup: rbac.authorization.k8s.io
</span><span class="s">  kind: Role
</span><span class="s">  name: nginx-ingress-role
</span><span class="s">subjects:
</span><span class="s">  - kind: ServiceAccount
</span><span class="s">    name: nginx-ingress-serviceaccount
</span><span class="s">    namespace: ingress-nginx
</span><span class="s">---
</span><span class="s">apiVersion: rbac.authorization.k8s.io/v1beta1
</span><span class="s">kind: ClusterRoleBinding
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-clusterrole-nisa-binding
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">roleRef:
</span><span class="s">  apiGroup: rbac.authorization.k8s.io
</span><span class="s">  kind: ClusterRole
</span><span class="s">  name: nginx-ingress-clusterrole
</span><span class="s">subjects:
</span><span class="s">  - kind: ServiceAccount
</span><span class="s">    name: nginx-ingress-serviceaccount
</span><span class="s">    namespace: ingress-nginx
</span><span class="s">---
</span><span class="s">apiVersion: apps/v1
</span><span class="s">kind: DaemonSet
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-controller
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">spec:
</span><span class="s">  selector:
</span><span class="s">    matchLabels:
</span><span class="s">      app.kubernetes.io/name: ingress-nginx
</span><span class="s">      app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">  template:
</span><span class="s">    metadata:
</span><span class="s">      labels:
</span><span class="s">        app.kubernetes.io/name: ingress-nginx
</span><span class="s">        app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">      annotations:
</span><span class="s">        prometheus.io/port: &#34;10254&#34;
</span><span class="s">        prometheus.io/scrape: &#34;true&#34;
</span><span class="s">    spec:
</span><span class="s">      # wait up to five minutes for the drain of connections
</span><span class="s">      terminationGracePeriodSeconds: 300
</span><span class="s">      serviceAccountName: nginx-ingress-serviceaccount
</span><span class="s">      nodeSelector:
</span><span class="s">        kubernetes.io/os: linux
</span><span class="s">      containers:
</span><span class="s">        - name: nginx-ingress-controller
</span><span class="s">          image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.26.1
</span><span class="s">          args:
</span><span class="s">            - /nginx-ingress-controller
</span><span class="s">            - --configmap=$(POD_NAMESPACE)/nginx-configuration
</span><span class="s">            - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services
</span><span class="s">            - --udp-services-configmap=$(POD_NAMESPACE)/udp-services
</span><span class="s">            - --publish-service=$(POD_NAMESPACE)/ingress-nginx
</span><span class="s">            - --annotations-prefix=nginx.ingress.kubernetes.io
</span><span class="s">          securityContext:
</span><span class="s">            allowPrivilegeEscalation: true
</span><span class="s">            capabilities:
</span><span class="s">              drop:
</span><span class="s">                - ALL
</span><span class="s">              add:
</span><span class="s">                - NET_BIND_SERVICE
</span><span class="s">            # www-data -&gt; 33
</span><span class="s">            runAsUser: 33
</span><span class="s">          env:
</span><span class="s">            - name: POD_NAME
</span><span class="s">              valueFrom:
</span><span class="s">                fieldRef:
</span><span class="s">                  fieldPath: metadata.name
</span><span class="s">            - name: POD_NAMESPACE
</span><span class="s">              valueFrom:
</span><span class="s">                fieldRef:
</span><span class="s">                  fieldPath: metadata.namespace
</span><span class="s">          ports:
</span><span class="s">            - name: http
</span><span class="s">              containerPort: 80
</span><span class="s">            - name: https
</span><span class="s">              containerPort: 443
</span><span class="s">          livenessProbe:
</span><span class="s">            failureThreshold: 3
</span><span class="s">            httpGet:
</span><span class="s">              path: /healthz
</span><span class="s">              port: 10254
</span><span class="s">              scheme: HTTP
</span><span class="s">            initialDelaySeconds: 10
</span><span class="s">            periodSeconds: 10
</span><span class="s">            successThreshold: 1
</span><span class="s">            timeoutSeconds: 10
</span><span class="s">          readinessProbe:
</span><span class="s">            failureThreshold: 3
</span><span class="s">            httpGet:
</span><span class="s">              path: /healthz
</span><span class="s">              port: 10254
</span><span class="s">              scheme: HTTP
</span><span class="s">            periodSeconds: 10
</span><span class="s">            successThreshold: 1
</span><span class="s">            timeoutSeconds: 10
</span><span class="s">          lifecycle:
</span><span class="s">            preStop:
</span><span class="s">              exec:
</span><span class="s">                command:
</span><span class="s">                  - /wait-shutdown
</span><span class="s">---
</span><span class="s">apiVersion: v1
</span><span class="s">kind: Service
</span><span class="s">metadata:
</span><span class="s">  name: nginx-ingress-controller
</span><span class="s">  namespace: ingress-nginx
</span><span class="s">  labels:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">spec:
</span><span class="s">  type: LoadBalancer
</span><span class="s">  externalTrafficPolicy: Local
</span><span class="s">  selector:
</span><span class="s">    app.kubernetes.io/name: ingress-nginx
</span><span class="s">    app.kubernetes.io/part-of: ingress-nginx
</span><span class="s">  ports:
</span><span class="s">    - name: http
</span><span class="s">      port: 80
</span><span class="s">      protocol: TCP
</span><span class="s">      targetPort: 80
</span><span class="s">    - name: https
</span><span class="s">      port: 443
</span><span class="s">      protocol: TCP
</span><span class="s">      targetPort: 443
</span><span class="s">EOF</span>
</code></pre></td></tr></table>
</div>
</div><p>部署</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ kubectl apply -f ingress-nginx.yaml  <span class="c1"># 执行部署</span>
namespace/ingress-nginx created
configmap/nginx-configuration created
configmap/tcp-services created
configmap/udp-services created
serviceaccount/nginx-ingress-serviceaccount created
clusterrole.rbac.authorization.k8s.io/nginx-ingress-clusterrole created
role.rbac.authorization.k8s.io/nginx-ingress-role created
rolebinding.rbac.authorization.k8s.io/nginx-ingress-role-nisa-binding created
clusterrolebinding.rbac.authorization.k8s.io/nginx-ingress-clusterrole-nisa-binding created
daemonset.apps/nginx-ingress-controller created
service/nginx-ingress-controller created
$ kubectl get pods -n ingress-nginx  <span class="c1"># 查看pod运行状态</span>
NAME                             READY   STATUS    RESTARTS   AGE
nginx-ingress-controller-2hc8m   1/1     Running   <span class="m">0</span>          4m36s
nginx-ingress-controller-69rfm   1/1     Running   <span class="m">0</span>          4m36s
nginx-ingress-controller-ps7gt   1/1     Running   <span class="m">0</span>          4m36s
nginx-ingress-controller-zfq56   1/1     Running   <span class="m">0</span>          4m36s
$ kubectl get service -n ingress-nginx  <span class="c1"># 查看service状态</span>
NAME                       TYPE           CLUSTER-IP     EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>                      AGE
nginx-ingress-controller   LoadBalancer   10.96.76.163   &lt;pending&gt;     80:31832/TCP,443:30219/TCP   6m10s
</code></pre></td></tr></table>
</div>
</div><p>此时发现 pod 已经正常运行了，但是 service 的 EXTERNAL-IP 字段却是 pending 状态</p>
<p>这是由于我们集群中还没有能处理 <code>LoadBalancer</code> 类型 service 的程序</p>
<p>在云环境中都会有个额外的组件 <code>Cloud-Controller-Manager(CCM)</code> 来对接云平台的负载均衡服务，如阿里云的 SLB，AWS 的 ALB 等</p>
<p>那么线下环境有没有办法实现类似 CCM 的功能呢，答案是 <code>metallb</code></p>
<h2 id="部署-metallb">部署 Metallb</h2>
<p>metallb 是一款为祼机 Kubernetes 环境提供标准路由协议的开源软负载均衡器，支持基于二层网络 ARP 或基于 BGP 方式进行地址广播</p>
<p>更详细的介绍请参考<a href="https://metallb.universe.tf/" target="_blank" rel="noopener noreffer">官方文档</a>或<a href="https://github.com/danderson/metallb" target="_blank" rel="noopener noreffer">Github</a></p>
<p>关于裸机下基于 Metallb 的负载均衡方案可参考 ingress-nginx 官方文档 <a href="https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#a-pure-software-solution-metallb" target="_blank" rel="noopener noreffer">A pure software solution: MetalLB</a></p>
<p>由于当前的物理环境中不支持 BGP，所以使用最简单的二层 ARP 方式</p>
<p>部署:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ kubectl apply -f https://raw.githubusercontent.com/google/metallb/v0.8.3/manifests/metallb.yaml
namespace/metallb-system created
podsecuritypolicy.policy/speaker created
serviceaccount/controller created
serviceaccount/speaker created
clusterrole.rbac.authorization.k8s.io/metallb-system:controller created
clusterrole.rbac.authorization.k8s.io/metallb-system:speaker created
role.rbac.authorization.k8s.io/config-watcher created
clusterrolebinding.rbac.authorization.k8s.io/metallb-system:controller created
clusterrolebinding.rbac.authorization.k8s.io/metallb-system:speaker created
rolebinding.rbac.authorization.k8s.io/config-watcher created
daemonset.apps/speaker created
deployment.apps/controller created
$ kubectl get pods -n metallb-system
NAME                          READY   STATUS    RESTARTS   AGE
controller-65895b47d4-fbs7t   1/1     Running   <span class="m">0</span>          3m21s
speaker-2skdk                 1/1     Running   <span class="m">0</span>          3m21s
speaker-6mg76                 1/1     Running   <span class="m">0</span>          3m21s
speaker-7rr8q                 1/1     Running   <span class="m">0</span>          3m21s
speaker-dv2rh                 1/1     Running   <span class="m">0</span>          3m21s
speaker-mwkqr                 1/1     Running   <span class="m">0</span>          3m21s
</code></pre></td></tr></table>
</div>
</div><p>创建配置文件</p>
<p>addresses 表示 LoadBalancer 可使用的 IP 池范围</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ cat &gt; metallb-configmap.yaml <span class="s">&lt;&lt;EOF
</span><span class="s">apiVersion: v1
</span><span class="s">kind: ConfigMap
</span><span class="s">metadata:
</span><span class="s">  namespace: metallb-system
</span><span class="s">  name: config
</span><span class="s">data:
</span><span class="s">  config: |
</span><span class="s">    address-pools:
</span><span class="s">    - name: default
</span><span class="s">      protocol: layer2
</span><span class="s">      addresses:
</span><span class="s">      - 10.64.144.150-10.64.144.250
</span><span class="s">EOF</span>
$ kubectl apply -f metallb-configmap.yaml
configmap/config created
</code></pre></td></tr></table>
</div>
</div><p>而此时再去查看 ingree-nginx 的 service 可以发现已经 EXTERNAL-IP 字段已经能正常拿到 IP 了</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ kubectl get service -n ingress-nginx
NAME                       TYPE           CLUSTER-IP     EXTERNAL-IP     PORT<span class="o">(</span>S<span class="o">)</span>                      AGE
nginx-ingress-controller   LoadBalancer   10.96.76.163   10.64.144.150   80:31832/TCP,443:30219/TCP   50m
</code></pre></td></tr></table>
</div>
</div><h2 id="测试-ingress-nginx-及-metallb">测试 ingress-nginx 及 metallb</h2>
<p>前面已经创建了 ingress-nginx 及 metallb,但到目前为止也只是看到了集群中的状态，并不能说明它俩是真的可用</p>
<p>所以我们来创建一个简单的应用来测试下</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span><span class="lnt">89
</span><span class="lnt">90
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-shell" data-lang="shell">$ cat &gt; nginx-test.yaml <span class="s">&lt;&lt;EOF
</span><span class="s">---
</span><span class="s">apiVersion: v1
</span><span class="s">kind: Service
</span><span class="s">metadata:
</span><span class="s">  creationTimestamp: null
</span><span class="s">  name: nginx
</span><span class="s">  labels:
</span><span class="s">    run: nginx
</span><span class="s">spec:
</span><span class="s">  ports:
</span><span class="s">  - port: 80
</span><span class="s">    protocol: TCP
</span><span class="s">    targetPort: 80
</span><span class="s">    name: http
</span><span class="s">  selector:
</span><span class="s">    run: nginx
</span><span class="s">status:
</span><span class="s">  loadBalancer: {}
</span><span class="s">---
</span><span class="s">apiVersion: apps/v1
</span><span class="s">kind: Deployment
</span><span class="s">metadata:
</span><span class="s">  creationTimestamp: null
</span><span class="s">  labels:
</span><span class="s">    run: nginx
</span><span class="s">  name: nginx
</span><span class="s">spec:
</span><span class="s">  replicas: 1
</span><span class="s">  selector:
</span><span class="s">    matchLabels:
</span><span class="s">      run: nginx
</span><span class="s">  template:
</span><span class="s">    metadata:
</span><span class="s">      creationTimestamp: null
</span><span class="s">      labels:
</span><span class="s">        run: nginx
</span><span class="s">    spec:
</span><span class="s">      containers:
</span><span class="s">      - image: nginx:alpine
</span><span class="s">        name: nginx
</span><span class="s">        ports:
</span><span class="s">        - containerPort: 80
</span><span class="s">---
</span><span class="s">apiVersion: networking.k8s.io/v1beta1
</span><span class="s">kind: Ingress
</span><span class="s">metadata:
</span><span class="s">  name: nginx
</span><span class="s">  labels:
</span><span class="s">    run: nginx
</span><span class="s">spec:
</span><span class="s">  rules:
</span><span class="s">  - host: test.nginx.com
</span><span class="s">    http:
</span><span class="s">      paths:
</span><span class="s">      - path: /
</span><span class="s">        backend:
</span><span class="s">          serviceName: nginx
</span><span class="s">          servicePort: http
</span><span class="s">EOF</span>
$ kubectl apply -f nginx-test.yaml
service/nginx created
deployment.apps/nginx created
ingress.networking.k8s.io/nginx created
$ curl -H <span class="s1">&#39;Host: test.nginx.com&#39;</span> http://10.64.144.150 <span class="c1"># 在局域网中其他机器测试访问</span>
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
&lt;style&gt;
    body <span class="o">{</span>
        width: 35em<span class="p">;</span>
        margin: <span class="m">0</span> auto<span class="p">;</span>
        font-family: Tahoma, Verdana, Arial, sans-serif<span class="p">;</span>
    <span class="o">}</span>
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
&lt;p&gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&lt;/p&gt;

&lt;p&gt;For online documentation and support please refer to
&lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&#34;http://nginx.org/&#34;</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
Commercial support is available at
&lt;a <span class="nv">href</span><span class="o">=</span><span class="s2">&#34;http://nginx.com/&#34;</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thank you <span class="k">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre></td></tr></table>
</div>
</div><p>由此 ingress-nginx 及负载均衡器 Metallb 已经部署完成</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2020-05-20&nbsp;<a class="git-hash" href="https://github.com/linuxyunwei/linuxyunwei.com/commit/cd0d0922d62775898d2c76ce429f4737877385ce" target="_blank" title="commit by Xijun Dai(daixijun1990@gmail.com) cd0d0922d62775898d2c76ce429f4737877385ce: feat: 添加 algolia 搜索">
                                    <i class="fas fa-hashtag fa-fw"></i>cd0d092</a></span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/kubernetes/">kubernetes</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"></div>
</div>
<div id="comments"><div id="gitalk" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://github.com/gitalk/gitalk"></a>Gitalk</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line"><a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=31011202011734"><img src="//p.ssl.qhmsg.com/t01d8eda6e551cf2615.png"/>沪公网安备 31011202011734号</p></a></div><div class="footer-line">由 <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.70.0">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.9"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2019 - 2020</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">戴先森</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span><span class="icp-splitter">&nbsp;|&nbsp;</span><br class="icp-br"/>
                    <span class="icp">沪ICP备13017200号</span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/gitalk/gitalk.min.css"><link rel="stylesheet" href="/lib/lightgallery/lightgallery.min.css"><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><style>.lg-toolbar .lg-icon::after { color: #999; }</style><script type="text/javascript" src="/lib/gitalk/gitalk.min.js"></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/algoliasearch/algoliasearch-lite.umd.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lightgallery.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-thumbnail.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-zoom.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/lib/cookieconsent/cookieconsent.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":50},"comment":{"gitalk":{"admin":["linuxyunwei"],"clientID":"e0ebb50b7471a999a10f","clientSecret":"1c47fb3b5af8c3f7840e0e8a8cd5b69ee10b682f","id":"2019-11-18T19:12:02+08:00","owner":"linuxyunwei","repo":"linuxyunwei.com","title":"kubeadm 安装单master集群"}},"cookieconsent":{"content":{"dismiss":"同意","link":"了解更多","message":"本网站使用 Cookies 来改善您的浏览体验."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"QK0DPR8U9U","algoliaIndex":"linuxyunwei.com","algoliaSearchKey":"ed629decd2fd8c246289576b705eb412","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
